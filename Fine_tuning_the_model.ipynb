{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **安装包**"
      ],
      "metadata": {
        "id": "1yUDOseoO41R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D6vWjmzz0ZTV"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers\n",
        "# !pip install datasets\n",
        "# !pip install accelerate -U\n",
        "# !pip install transformers[torch]\n",
        "# !pip install sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **导入需要的包**"
      ],
      "metadata": {
        "id": "smZJV4Q6MIFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "from datasets import load_dataset\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "from transformers import T5Tokenizer"
      ],
      "metadata": {
        "id": "gMCnNZxY5Zy0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **加载数据**"
      ],
      "metadata": {
        "id": "xvjE-aLGJ9Kr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# 指向数据集文件的路径\n",
        "dataset_path = \"/content/drive/MyDrive/CSpider\"\n",
        "\n",
        "# 读取训练数据\n",
        "with open(f\"{dataset_path}/train.json\", \"r\", encoding=\"utf-8\") as train_file:\n",
        "    train_data = json.load(train_file)\n",
        "\n",
        "# 读取验证数据\n",
        "with open(f\"{dataset_path}/dev.json\", \"r\", encoding=\"utf-8\") as validation_file:\n",
        "    validation_data = json.load(validation_file)\n",
        "\n",
        "# 现在你可以使用 train_data 和 validation_data 进行进一步的处理，以适应你的项目需求。\n"
      ],
      "metadata": {
        "id": "Nju3qE275n2t"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **数据集处理**"
      ],
      "metadata": {
        "id": "O4YduKmrKA-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 初始化 T5 tokenizer\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "\n",
        "# 将数据转换为适合 T5 模型的格式\n",
        "formatted_data = []\n",
        "labels = []  # 存储目标 SQL 查询的列表\n",
        "for example in train_data:\n",
        "    question = example[\"question\"]\n",
        "    query = \" \".join(example[\"query_toks\"])\n",
        "    formatted_data.append(f\"question: {question} context: {query}\")\n",
        "    # 添加目标 SQL 查询到 labels 列表\n",
        "    # label.append(example[\"sql\"])\n",
        "    sql_query = example[\"sql\"]\n",
        "    # 将 SQL 查询字典转换为字符串\n",
        "    sql_query_str = ' '.join(map(str, sql_query))\n",
        "    labels.append(sql_query_str)\n",
        "\n",
        "\n",
        "print(train_data[:10])\n",
        "print(formatted_data[:10])\n",
        "print(labels[:10])  # 打印前10个 SQL 查询作为 labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9nhpgO_m-y2",
        "outputId": "c40b2c97-9635-4225-b61d-f2bde32316ec"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'db_id': 'department_management', 'query_toks_no_value': ['select', 'count', '(', '*', ')', 'from', 'head', 'where', 'age', '>', 'value'], 'question_toks': ['部', '门', '中', '有', '多', '少', '人', '年', '龄', '大', '于', '5', '6', '岁', '？'], 'query_toks': ['select', 'count', '(', '*', ')', 'from', 'head', 'where', 'age', '>', '56'], 'question': '部门中有多少人年龄大于56岁？', 'sql': {'orderBy': [], 'from': {'table_units': [['table_unit', 1]], 'conds': []}, 'union': None, 'except': None, 'groupBy': [], 'limit': None, 'intersect': None, 'where': [[False, 3, [0, [0, 10, False], None], 56.0, None]], 'having': [], 'select': [False, [[3, [0, [0, 0, False], None]]]]}, 'query': 'SELECT count(*) FROM head WHERE age  >  56'}, {'db_id': 'department_management', 'query_toks_no_value': ['select', 'name', ',', 'born_state', ',', 'age', 'from', 'head', 'order', 'by', 'age'], 'question_toks': ['列', '出', '按', '年', '龄', '排', '序', '的', '部', '门', '负', '责', '人', '的', '姓', '名', '、', '出', '生', '地', '和', '年', '龄', '。'], 'query_toks': ['select', 'name', ',', 'born_state', ',', 'age', 'from', 'head', 'order', 'by', 'age'], 'question': '列出按年龄排序的部门负责人的姓名、出生地和年龄。', 'sql': {'orderBy': ['asc', [[0, [0, 10, False], None]]], 'from': {'table_units': [['table_unit', 1]], 'conds': []}, 'union': None, 'except': None, 'groupBy': [], 'limit': None, 'intersect': None, 'where': [], 'having': [], 'select': [False, [[0, [0, [0, 8, False], None]], [0, [0, [0, 9, False], None]], [0, [0, [0, 10, False], None]]]]}, 'query': 'SELECT name ,  born_state ,  age FROM head ORDER BY age'}, {'db_id': 'department_management', 'query_toks_no_value': ['select', 'creation', ',', 'name', ',', 'budget_in_billions', 'from', 'department'], 'question_toks': ['列', '出', '每', '个', '部', '门', '的', '创', '建', '年', '份', '、', '名', '称', '和', '预', '算', '。'], 'query_toks': ['select', 'creation', ',', 'name', ',', 'budget_in_billions', 'from', 'department'], 'question': '列出每个部门的创建年份、名称和预算。', 'sql': {'orderBy': [], 'from': {'table_units': [['table_unit', 0]], 'conds': []}, 'union': None, 'except': None, 'groupBy': [], 'limit': None, 'intersect': None, 'where': [], 'having': [], 'select': [False, [[0, [0, [0, 3, False], None]], [0, [0, [0, 2, False], None]], [0, [0, [0, 5, False], None]]]]}, 'query': 'SELECT creation ,  name ,  budget_in_billions FROM department'}, {'db_id': 'department_management', 'query_toks_no_value': ['select', 'max', '(', 'budget_in_billions', ')', ',', 'min', '(', 'budget_in_billions', ')', 'from', 'department'], 'question_toks': ['部', '门', '的', '最', '高', '预', '算', '和', '最', '低', '预', '算', '是', '多', '少', '？'], 'query_toks': ['select', 'max', '(', 'budget_in_billions', ')', ',', 'min', '(', 'budget_in_billions', ')', 'from', 'department'], 'question': '部门的最高预算和最低预算是多少？', 'sql': {'orderBy': [], 'from': {'table_units': [['table_unit', 0]], 'conds': []}, 'union': None, 'except': None, 'groupBy': [], 'limit': None, 'intersect': None, 'where': [], 'having': [], 'select': [False, [[1, [0, [0, 5, False], None]], [2, [0, [0, 5, False], None]]]]}, 'query': 'SELECT max(budget_in_billions) ,  min(budget_in_billions) FROM department'}, {'db_id': 'department_management', 'query_toks_no_value': ['select', 'avg', '(', 'num_employees', ')', 'from', 'department', 'where', 'ranking', 'between', 'value', 'and', 'value'], 'question_toks': ['排', '名', '在', '1', '0', '到', '1', '5', '之', '间', '的', '部', '门', '的', '平', '均', '雇', '员', '人', '数', '是', '多', '少', '？'], 'query_toks': ['select', 'avg', '(', 'num_employees', ')', 'from', 'department', 'where', 'ranking', 'between', '10', 'and', '15'], 'question': '排名在10到15之间的部门的平均雇员人数是多少？', 'sql': {'orderBy': [], 'from': {'table_units': [['table_unit', 0]], 'conds': []}, 'union': None, 'except': None, 'groupBy': [], 'limit': None, 'intersect': None, 'where': [[False, 1, [0, [0, 4, False], None], 10.0, 15.0]], 'having': [], 'select': [False, [[5, [0, [0, 6, False], None]]]]}, 'query': 'SELECT avg(num_employees) FROM department WHERE ranking BETWEEN 10 AND 15'}, {'db_id': 'department_management', 'query_toks_no_value': ['select', 'name', 'from', 'head', 'where', 'born_state', '!', '=', 'value'], 'question_toks': ['出', '生', '在', '“', '浙', '江', '”', '州', '以', '外', '的', '人', '的', '名', '字', '是', '什', '么', '？'], 'query_toks': ['select', 'name', 'from', 'head', 'where', 'born_state', '!=', '\"浙江\"'], 'question': '出生在“浙江”州以外的人的名字是什么？', 'sql': {'orderBy': [], 'from': {'table_units': [['table_unit', 1]], 'conds': []}, 'union': None, 'except': None, 'groupBy': [], 'limit': None, 'intersect': None, 'where': [[False, 7, [0, [0, 9, False], None], '\"浙江\"', None]], 'having': [], 'select': [False, [[0, [0, [0, 8, False], None]]]]}, 'query': \"SELECT name FROM head WHERE born_state != '浙江'\"}, {'db_id': 'department_management', 'query_toks_no_value': ['select', 'distinct', 't1', '.', 'creation', 'from', 'department', 'as', 't1', 'join', 'management', 'as', 't2', 'on', 't1', '.', 'department_id', '=', 't2', '.', 'department_id', 'join', 'head', 'as', 't3', 'on', 't2', '.', 'head_id', '=', 't3', '.', 'head_id', 'where', 't3', '.', 'born_state', '=', 'value'], 'question_toks': ['出', '生', '于', '“', '河', '南', '”', '州', '的', '秘', '书', '所', '管', '理', '的', '各', '部', '门', '的', '不', '同', '创', '建', '年', '份', '是', '什', '么', '？'], 'query_toks': ['select', 'distinct', 't1.creation', 'from', 'department', 'as', 't1', 'join', 'management', 'as', 't2', 'on', 't1.department_id', '=', 't2.department_id', 'join', 'head', 'as', 't3', 'on', 't2.head_id', '=', 't3.head_id', 'where', 't3.born_state', '=', '\"河南\"'], 'question': '出生于“河南”州的秘书所管理的各部门的不同创建年份是什么？', 'sql': {'orderBy': [], 'from': {'table_units': [['table_unit', 0], ['table_unit', 2], ['table_unit', 1]], 'conds': [[False, 2, [0, [0, 1, False], None], [0, 11, False], None], 'and', [False, 2, [0, [0, 12, False], None], [0, 7, False], None]]}, 'union': None, 'except': None, 'groupBy': [], 'limit': None, 'intersect': None, 'where': [[False, 2, [0, [0, 9, False], None], '\"河南\"', None]], 'having': [], 'select': [True, [[0, [0, [0, 3, False], None]]]]}, 'query': \"SELECT DISTINCT T1.creation FROM department AS T1 JOIN management AS T2 ON T1.department_id  =  T2.department_id JOIN head AS T3 ON T2.head_id  =  T3.head_id WHERE T3.born_state  =  '河南'\"}, {'db_id': 'department_management', 'query_toks_no_value': ['select', 'born_state', 'from', 'head', 'group', 'by', 'born_state', 'having', 'count', '(', '*', ')', '>', '=', 'value'], 'question_toks': ['至', '少', '有', '3', '个', '负', '责', '人', '出', '生', '的', '州', '的', '名', '字', '是', '什', '么', '？'], 'query_toks': ['select', 'born_state', 'from', 'head', 'group', 'by', 'born_state', 'having', 'count', '(', '*', ')', '>=', '3'], 'question': '至少有3个负责人出生的州的名字是什么？', 'sql': {'orderBy': [], 'from': {'table_units': [['table_unit', 1]], 'conds': []}, 'union': None, 'except': None, 'groupBy': [[0, 9, False]], 'limit': None, 'intersect': None, 'where': [], 'having': [[False, 5, [0, [3, 0, False], None], 3.0, None]], 'select': [False, [[0, [0, [0, 9, False], None]]]]}, 'query': 'SELECT born_state FROM head GROUP BY born_state HAVING count(*)  >=  3'}, {'db_id': 'department_management', 'query_toks_no_value': ['select', 'creation', 'from', 'department', 'group', 'by', 'creation', 'order', 'by', 'count', '(', '*', ')', 'desc', 'limit', 'value'], 'question_toks': ['大', '多', '数', '部', '门', '在', '哪', '一', '年', '成', '立', '？'], 'query_toks': ['select', 'creation', 'from', 'department', 'group', 'by', 'creation', 'order', 'by', 'count', '(', '*', ')', 'desc', 'limit', '1'], 'question': '大多数部门在哪一年成立？', 'sql': {'orderBy': ['desc', [[0, [3, 0, False], None]]], 'from': {'table_units': [['table_unit', 0]], 'conds': []}, 'union': None, 'except': None, 'groupBy': [[0, 3, False]], 'limit': 1, 'intersect': None, 'where': [], 'having': [], 'select': [False, [[0, [0, [0, 3, False], None]]]]}, 'query': 'SELECT creation FROM department GROUP BY creation ORDER BY count(*) DESC LIMIT 1'}, {'db_id': 'department_management', 'query_toks_no_value': ['select', 't1', '.', 'name', ',', 't1', '.', 'num_employees', 'from', 'department', 'as', 't1', 'join', 'management', 'as', 't2', 'on', 't1', '.', 'department_id', '=', 't2', '.', 'department_id', 'where', 't2', '.', 'temporary_acting', '=', 'value'], 'question_toks': ['显', '示', '由', '临', '时', '代', '理', '值', '为', '“', '是', '”', '的', '负', '责', '人', '所', '管', '理', '的', '部', '门', '的', '员', '工', '姓', '名', '和', '数', '目', '？'], 'query_toks': ['select', 't1.name', ',', 't1.num_employees', 'from', 'department', 'as', 't1', 'join', 'management', 'as', 't2', 'on', 't1.department_id', '=', 't2.department_id', 'where', 't2.temporary_acting', '=', '\"是\"'], 'question': '显示由临时代理值为“是”的负责人所管理的部门的员工姓名和数目？', 'sql': {'orderBy': [], 'from': {'table_units': [['table_unit', 0], ['table_unit', 2]], 'conds': [[False, 2, [0, [0, 1, False], None], [0, 11, False], None]]}, 'union': None, 'except': None, 'groupBy': [], 'limit': None, 'intersect': None, 'where': [[False, 2, [0, [0, 13, False], None], '\"是\"', None]], 'having': [], 'select': [False, [[0, [0, [0, 2, False], None]], [0, [0, [0, 6, False], None]]]]}, 'query': \"SELECT T1.name ,  T1.num_employees FROM department AS T1 JOIN management AS T2 ON T1.department_id  =  T2.department_id WHERE T2.temporary_acting  =  '是'\"}]\n",
            "['question: 部门中有多少人年龄大于56岁？ context: select count ( * ) from head where age > 56', 'question: 列出按年龄排序的部门负责人的姓名、出生地和年龄。 context: select name , born_state , age from head order by age', 'question: 列出每个部门的创建年份、名称和预算。 context: select creation , name , budget_in_billions from department', 'question: 部门的最高预算和最低预算是多少？ context: select max ( budget_in_billions ) , min ( budget_in_billions ) from department', 'question: 排名在10到15之间的部门的平均雇员人数是多少？ context: select avg ( num_employees ) from department where ranking between 10 and 15', 'question: 出生在“浙江”州以外的人的名字是什么？ context: select name from head where born_state != \"浙江\"', 'question: 出生于“河南”州的秘书所管理的各部门的不同创建年份是什么？ context: select distinct t1.creation from department as t1 join management as t2 on t1.department_id = t2.department_id join head as t3 on t2.head_id = t3.head_id where t3.born_state = \"河南\"', 'question: 至少有3个负责人出生的州的名字是什么？ context: select born_state from head group by born_state having count ( * ) >= 3', 'question: 大多数部门在哪一年成立？ context: select creation from department group by creation order by count ( * ) desc limit 1', 'question: 显示由临时代理值为“是”的负责人所管理的部门的员工姓名和数目？ context: select t1.name , t1.num_employees from department as t1 join management as t2 on t1.department_id = t2.department_id where t2.temporary_acting = \"是\"']\n",
            "['orderBy from union except groupBy limit intersect where having select', 'orderBy from union except groupBy limit intersect where having select', 'orderBy from union except groupBy limit intersect where having select', 'orderBy from union except groupBy limit intersect where having select', 'orderBy from union except groupBy limit intersect where having select', 'orderBy from union except groupBy limit intersect where having select', 'orderBy from union except groupBy limit intersect where having select', 'orderBy from union except groupBy limit intersect where having select', 'orderBy from union except groupBy limit intersect where having select', 'orderBy from union except groupBy limit intersect where having select']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **编码数据**"
      ],
      "metadata": {
        "id": "QcPPfZLZMRl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 编码数据\n",
        "input_ids = tokenizer(formatted_data, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "print(input_ids)\n",
        "\n",
        "# 编码 SQL 查询\n",
        "# labels = tokenizer(label, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "labels = tokenizer(labels, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "print(labels[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZLq8BcYnKEq",
        "outputId": "9c5b6e62-c56d-4298-b42e-fbc9bc9f1eb7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[822,  10,   3,  ...,   0,   0,   0],\n",
            "        [822,  10,   3,  ...,   0,   0,   0],\n",
            "        [822,  10,   3,  ...,   0,   0,   0],\n",
            "        ...,\n",
            "        [822,  10, 105,  ...,   0,   0,   0],\n",
            "        [822,  10,   3,  ...,   0,   0,   0],\n",
            "        [822,  10, 105,  ...,   0,   0,   0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
            "{'input_ids': tensor([[  455,   279,    63,    45,  7021,  3578,   563,   279,    63,  2006,\n",
            "         27806,   213,   578,  1738,     1],\n",
            "        [  455,   279,    63,    45,  7021,  3578,   563,   279,    63,  2006,\n",
            "         27806,   213,   578,  1738,     1],\n",
            "        [  455,   279,    63,    45,  7021,  3578,   563,   279,    63,  2006,\n",
            "         27806,   213,   578,  1738,     1],\n",
            "        [  455,   279,    63,    45,  7021,  3578,   563,   279,    63,  2006,\n",
            "         27806,   213,   578,  1738,     1],\n",
            "        [  455,   279,    63,    45,  7021,  3578,   563,   279,    63,  2006,\n",
            "         27806,   213,   578,  1738,     1],\n",
            "        [  455,   279,    63,    45,  7021,  3578,   563,   279,    63,  2006,\n",
            "         27806,   213,   578,  1738,     1],\n",
            "        [  455,   279,    63,    45,  7021,  3578,   563,   279,    63,  2006,\n",
            "         27806,   213,   578,  1738,     1],\n",
            "        [  455,   279,    63,    45,  7021,  3578,   563,   279,    63,  2006,\n",
            "         27806,   213,   578,  1738,     1],\n",
            "        [  455,   279,    63,    45,  7021,  3578,   563,   279,    63,  2006,\n",
            "         27806,   213,   578,  1738,     1],\n",
            "        [  455,   279,    63,    45,  7021,  3578,   563,   279,    63,  2006,\n",
            "         27806,   213,   578,  1738,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 确保数据包含 input_ids 和 attention_mask 字段\n",
        "train_dataset = {\n",
        "    \"input_ids\": input_ids[\"input_ids\"],\n",
        "    \"attention_mask\": input_ids[\"attention_mask\"],\n",
        "    \"labels\": labels,  # T5 模型要求预测标签与输入相同\n",
        "}\n",
        "\n",
        "\n",
        "for i, (key, value) in enumerate(train_dataset.items()):\n",
        "    if i >= 10:\n",
        "        break\n",
        "    print(f\"{key}: {value}\")\n",
        "# train_dataset 现在包含了适合微调 T5 模型的数据"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOIepI-OnNnA",
        "outputId": "159a5a14-914b-4969-80a0-9afdb5faf690"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids: tensor([[822,  10,   3,  ...,   0,   0,   0],\n",
            "        [822,  10,   3,  ...,   0,   0,   0],\n",
            "        [822,  10,   3,  ...,   0,   0,   0],\n",
            "        ...,\n",
            "        [822,  10, 105,  ...,   0,   0,   0],\n",
            "        [822,  10,   3,  ...,   0,   0,   0],\n",
            "        [822,  10, 105,  ...,   0,   0,   0]])\n",
            "attention_mask: tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]])\n",
            "labels: {'input_ids': tensor([[ 455,  279,   63,  ...,  578, 1738,    1],\n",
            "        [ 455,  279,   63,  ...,  578, 1738,    1],\n",
            "        [ 455,  279,   63,  ...,  578, 1738,    1],\n",
            "        ...,\n",
            "        [ 455,  279,   63,  ...,  578, 1738,    1],\n",
            "        [ 455,  279,   63,  ...,  578, 1738,    1],\n",
            "        [ 455,  279,   63,  ...,  578, 1738,    1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **加载模型**"
      ],
      "metadata": {
        "id": "jTG-ZQgiMYnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 加载微调所需的模型和tokenizer\n",
        "model_name = \"tscholak/2jrayxos\"  # 替换为你的预训练模型的名称\n",
        "tokenizer_name = \"tscholak/2jrayxos\"  # 替换为你的预训练模型的tokenizer名称\n",
        "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzGmO9sI8NDx",
        "outputId": "23b47046-3ae1-43cf-d15f-ee09ff41af50"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **数据编码**"
      ],
      "metadata": {
        "id": "9AAusp3iK5Aa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "# 准备微调数据\n",
        "formatted_data = []\n",
        "\n",
        "for example in train_data:\n",
        "    inputs = example[\"question\"]\n",
        "    targets = \" \".join(example[\"sql\"])  # 将SQL查询字符串列表合并为一个字符串\n",
        "    # input_encodings = tokenizer(\"question: \" + inputs, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "    input_encodings = tokenizer(\"question: \" + inputs, targets, truncation=True, padding=\"max_length\", max_length=64, return_tensors=\"pt\")\n",
        "    target_encodings = tokenizer(targets, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "\n",
        "    formatted_data.append({\n",
        "        \"input_ids\": input_encodings.input_ids[0],\n",
        "        \"attention_mask\": input_encodings.attention_mask[0],\n",
        "        \"labels\": target_encodings.input_ids[0],\n",
        "    })\n",
        "\n",
        "# 创建数据集\n",
        "train_dataset = formatted_data"
      ],
      "metadata": {
        "id": "Nn3hvklM0nD4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **定义数据收集器**"
      ],
      "metadata": {
        "id": "3Y9DzFxEMc97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义数据收集器\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer,\n",
        "    model=model,\n",
        ")"
      ],
      "metadata": {
        "id": "e_v1peeo8pS_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **定义微调参数**"
      ],
      "metadata": {
        "id": "Xu2v1EZ7MguF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义微调参数\n",
        "# training_args = Seq2SeqTrainingArguments(\n",
        "#     output_dir=\"./cspider_finetuned_model\",\n",
        "#     per_device_train_batch_size=8,\n",
        "#     num_train_epochs=3,\n",
        "#     evaluation_strategy=\"steps\",\n",
        "#     save_steps=1000,\n",
        "#     eval_steps=1000,\n",
        "#     logging_dir=\"./logs\",\n",
        "#     logging_steps=10,\n",
        "#     save_total_limit=2,\n",
        "# )\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./cspider_finetuned_model\",\n",
        "    per_device_train_batch_size=2,\n",
        "    num_train_epochs=3,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    save_steps=1000,\n",
        "    eval_steps=1000,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    save_total_limit=2,\n",
        "    fp16=True  # 启用混合精度训练\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "IouvnbTw8sWR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **初始化微调器**"
      ],
      "metadata": {
        "id": "oK0EDASAMkqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 初始化微调器\n",
        "# trainer = Seq2SeqTrainer(\n",
        "#     model=model,\n",
        "#     args=training_args,\n",
        "#     data_collator=data_collator,\n",
        "#     train_dataset=train_data,\n",
        "# )\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "6r2brxUh8mqj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(train_dataset)\n",
        "print(len(train_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDo4aHHMOXn2",
        "outputId": "bb72cda5-edcc-4486-9599-a43df508d9f3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 开始微调\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "DNMLO4od8dBV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "outputId": "05479836-d6f0-442c-f743-8845ca263a72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='436' max='12990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  436/12990 04:23 < 2:07:07, 1.65 it/s, Epoch 0.10/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 保存微调后的模型\n",
        "trainer.save_model(\"./cspider_finetuned_model\")"
      ],
      "metadata": {
        "id": "MvKk4Tcs8ewz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}