{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83695073acf0b5a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T05:11:49.326557900Z",
     "start_time": "2023-12-02T05:11:45.713104700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying token against https://api.modal.com\n",
      "Token verified successfully\n",
      "Token written to C:\\Users\\汽车/.modal.toml\n"
     ]
    }
   ],
   "source": [
    "!modal token set --token-id ak-uYihUyljHUMHQvSuKHjxDL --token-secret as-PNcBevbbT2feBCxTHYSjsK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93ad6fe5af7629e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# gpu_info = !nvidia-smi\n",
    "# gpu_info = '\\n'.join(gpu_info)\n",
    "# if gpu_info.find('failed') >= 0:\n",
    "#   print('Not connected to a GPU')\n",
    "# else:\n",
    "#   print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb41fd1c4526a6d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80697aeb2fc32ee1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # 更改当前的工作目录到您的项目目录\n",
    "# import os\n",
    "# os.chdir('/content/drive/MyDrive/modal_finetune_sql')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b21b382c90d6fb9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Finetuning LLaMa + Text-to-SQL\n",
    "\n",
    "This walkthrough shows you how to fine-tune LLaMa-7B on a Text-to-SQL dataset, and then use it for inference against\n",
    "any database of structured data using LlamaIndex.\n",
    "\n",
    "**NOTE**: This code is taken and adapted from Modal's `doppel-bot` repo: https://github.com/modal-labs/doppel-bot.\n",
    "**NOTE**: A lot of the code is contained in the underlying Python scripts in the `src` directory. We definitely encourage you to go and take a look!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd351afb864ab12",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Setup\n",
    "\n",
    "NOTE: you will need to setup a Modal account + token in order to use this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b9b3ef15acbb34b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T04:06:53.883546300Z",
     "start_time": "2023-12-02T04:06:48.704690900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting modal-client (from -r requirements.txt (line 1))\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/7c/dc/c0674f843af1f5675731a10a2124247796ec0e947c32f90679b355d51783/modal_client-0.55.4174-py3-none-any.whl (1.3 kB)\n",
      "Collecting llama-index==0.8.2.post1 (from -r requirements.txt (line 2))\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/91/ee/590f6f6d5ba81eb8c08c9a98dad290f983d0f609e51723821b3684f468a1/llama_index-0.8.2.post1-py3-none-any.whl (676 kB)\n",
      "Collecting datasets>=2.15.0 (from -r requirements.txt (line 3))\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/e2/cf/db41e572d7ed958e8679018f8190438ef700aeb501b62da9e1eed9e4d69a/datasets-2.15.0-py3-none-any.whl (521 kB)\n",
      "Requirement already satisfied: peft in d:\\python\\lib\\site-packages (from -r requirements.txt (line 4)) (0.5.0)\n",
      "Collecting tiktoken (from llama-index==0.8.2.post1->-r requirements.txt (line 2))\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/16/af/3dfa09ac7486dc9fb23eb5b57425bba6049583a66b319f68e4a3abf80498/tiktoken-0.5.1-cp38-cp38-win_amd64.whl (759 kB)\n",
      "Collecting dataclasses-json (from llama-index==0.8.2.post1->-r requirements.txt (line 2))\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/ae/53/8c006de775834cd4ea64a445402dc195caeebb77dc76b7defb9b3887cb0d/dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
      "INFO: pip is looking at multiple versions of llama-index to determine which version is compatible with other requirements. This could take a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Ignored the following versions that require a different python version: 0.0.100 Requires-Python >=3.8.1,<4.0; 0.0.101 Requires-Python >=3.8.1,<4.0; 0.0.101rc0 Requires-Python >=3.8.1,<4.0; 0.0.102 Requires-Python >=3.8.1,<4.0; 0.0.102rc0 Requires-Python >=3.8.1,<4.0; 0.0.103 Requires-Python >=3.8.1,<4.0; 0.0.104 Requires-Python >=3.8.1,<4.0; 0.0.105 Requires-Python >=3.8.1,<4.0; 0.0.106 Requires-Python >=3.8.1,<4.0; 0.0.107 Requires-Python >=3.8.1,<4.0; 0.0.108 Requires-Python >=3.8.1,<4.0; 0.0.109 Requires-Python >=3.8.1,<4.0; 0.0.110 Requires-Python >=3.8.1,<4.0; 0.0.111 Requires-Python >=3.8.1,<4.0; 0.0.112 Requires-Python >=3.8.1,<4.0; 0.0.113 Requires-Python >=3.8.1,<4.0; 0.0.114 Requires-Python >=3.8.1,<4.0; 0.0.115 Requires-Python >=3.8.1,<4.0; 0.0.116 Requires-Python >=3.8.1,<4.0; 0.0.117 Requires-Python >=3.8.1,<4.0; 0.0.118 Requires-Python >=3.8.1,<4.0; 0.0.119 Requires-Python >=3.8.1,<4.0; 0.0.120 Requires-Python >=3.8.1,<4.0; 0.0.121 Requires-Python >=3.8.1,<4.0; 0.0.122 Requires-Python >=3.8.1,<4.0; 0.0.123 Requires-Python >=3.8.1,<4.0; 0.0.124 Requires-Python >=3.8.1,<4.0; 0.0.125 Requires-Python >=3.8.1,<4.0; 0.0.126 Requires-Python >=3.8.1,<4.0; 0.0.127 Requires-Python >=3.8.1,<4.0; 0.0.128 Requires-Python >=3.8.1,<4.0; 0.0.129 Requires-Python >=3.8.1,<4.0; 0.0.130 Requires-Python >=3.8.1,<4.0; 0.0.131 Requires-Python >=3.8.1,<4.0; 0.0.132 Requires-Python >=3.8.1,<4.0; 0.0.133 Requires-Python >=3.8.1,<4.0; 0.0.134 Requires-Python >=3.8.1,<4.0; 0.0.135 Requires-Python >=3.8.1,<4.0; 0.0.136 Requires-Python >=3.8.1,<4.0; 0.0.137 Requires-Python >=3.8.1,<4.0; 0.0.138 Requires-Python >=3.8.1,<4.0; 0.0.139 Requires-Python >=3.8.1,<4.0; 0.0.140 Requires-Python >=3.8.1,<4.0; 0.0.141 Requires-Python >=3.8.1,<4.0; 0.0.142 Requires-Python >=3.8.1,<4.0; 0.0.143 Requires-Python >=3.8.1,<4.0; 0.0.144 Requires-Python >=3.8.1,<4.0; 0.0.145 Requires-Python >=3.8.1,<4.0; 0.0.146 Requires-Python >=3.8.1,<4.0; 0.0.147 Requires-Python >=3.8.1,<4.0; 0.0.148 Requires-Python >=3.8.1,<4.0; 0.0.149 Requires-Python >=3.8.1,<4.0; 0.0.150 Requires-Python >=3.8.1,<4.0; 0.0.151 Requires-Python >=3.8.1,<4.0; 0.0.152 Requires-Python >=3.8.1,<4.0; 0.0.153 Requires-Python >=3.8.1,<4.0; 0.0.154 Requires-Python >=3.8.1,<4.0; 0.0.155 Requires-Python >=3.8.1,<4.0; 0.0.156 Requires-Python >=3.8.1,<4.0; 0.0.157 Requires-Python >=3.8.1,<4.0; 0.0.158 Requires-Python >=3.8.1,<4.0; 0.0.159 Requires-Python >=3.8.1,<4.0; 0.0.160 Requires-Python >=3.8.1,<4.0; 0.0.161 Requires-Python >=3.8.1,<4.0; 0.0.162 Requires-Python >=3.8.1,<4.0; 0.0.163 Requires-Python >=3.8.1,<4.0; 0.0.164 Requires-Python >=3.8.1,<4.0; 0.0.165 Requires-Python >=3.8.1,<4.0; 0.0.166 Requires-Python >=3.8.1,<4.0; 0.0.167 Requires-Python >=3.8.1,<4.0; 0.0.168 Requires-Python >=3.8.1,<4.0; 0.0.169 Requires-Python >=3.8.1,<4.0; 0.0.170 Requires-Python >=3.8.1,<4.0; 0.0.171 Requires-Python >=3.8.1,<4.0; 0.0.172 Requires-Python >=3.8.1,<4.0; 0.0.173 Requires-Python >=3.8.1,<4.0; 0.0.174 Requires-Python >=3.8.1,<4.0; 0.0.175 Requires-Python >=3.8.1,<4.0; 0.0.176 Requires-Python >=3.8.1,<4.0; 0.0.177 Requires-Python >=3.8.1,<4.0; 0.0.178 Requires-Python >=3.8.1,<4.0; 0.0.179 Requires-Python >=3.8.1,<4.0; 0.0.180 Requires-Python >=3.8.1,<4.0; 0.0.181 Requires-Python >=3.8.1,<4.0; 0.0.182 Requires-Python >=3.8.1,<4.0; 0.0.183 Requires-Python >=3.8.1,<4.0; 0.0.184 Requires-Python >=3.8.1,<4.0; 0.0.185 Requires-Python >=3.8.1,<4.0; 0.0.186 Requires-Python >=3.8.1,<4.0; 0.0.187 Requires-Python >=3.8.1,<4.0; 0.0.188 Requires-Python >=3.8.1,<4.0; 0.0.189 Requires-Python >=3.8.1,<4.0; 0.0.190 Requires-Python >=3.8.1,<4.0; 0.0.191 Requires-Python >=3.8.1,<4.0; 0.0.192 Requires-Python >=3.8.1,<4.0; 0.0.193 Requires-Python >=3.8.1,<4.0; 0.0.194 Requires-Python >=3.8.1,<4.0; 0.0.195 Requires-Python >=3.8.1,<4.0; 0.0.196 Requires-Python >=3.8.1,<4.0; 0.0.197 Requires-Python >=3.8.1,<4.0; 0.0.198 Requires-Python >=3.8.1,<4.0; 0.0.199 Requires-Python >=3.8.1,<4.0; 0.0.200 Requires-Python >=3.8.1,<4.0; 0.0.201 Requires-Python >=3.8.1,<4.0; 0.0.202 Requires-Python >=3.8.1,<4.0; 0.0.203 Requires-Python >=3.8.1,<4.0; 0.0.204 Requires-Python >=3.8.1,<4.0; 0.0.205 Requires-Python >=3.8.1,<4.0; 0.0.206 Requires-Python >=3.8.1,<4.0; 0.0.207 Requires-Python >=3.8.1,<4.0; 0.0.208 Requires-Python >=3.8.1,<4.0; 0.0.209 Requires-Python >=3.8.1,<4.0; 0.0.210 Requires-Python >=3.8.1,<4.0; 0.0.211 Requires-Python >=3.8.1,<4.0; 0.0.212 Requires-Python >=3.8.1,<4.0; 0.0.213 Requires-Python >=3.8.1,<4.0; 0.0.214 Requires-Python >=3.8.1,<4.0; 0.0.215 Requires-Python >=3.8.1,<4.0; 0.0.216 Requires-Python >=3.8.1,<4.0; 0.0.217 Requires-Python >=3.8.1,<4.0; 0.0.218 Requires-Python >=3.8.1,<4.0; 0.0.219 Requires-Python >=3.8.1,<4.0; 0.0.220 Requires-Python >=3.8.1,<4.0; 0.0.221 Requires-Python >=3.8.1,<4.0; 0.0.222 Requires-Python >=3.8.1,<4.0; 0.0.223 Requires-Python >=3.8.1,<4.0; 0.0.224 Requires-Python >=3.8.1,<4.0; 0.0.225 Requires-Python >=3.8.1,<4.0; 0.0.226 Requires-Python >=3.8.1,<4.0; 0.0.227 Requires-Python >=3.8.1,<4.0; 0.0.228 Requires-Python >=3.8.1,<4.0; 0.0.229 Requires-Python >=3.8.1,<4.0; 0.0.230 Requires-Python >=3.8.1,<4.0; 0.0.231 Requires-Python >=3.8.1,<4.0; 0.0.232 Requires-Python >=3.8.1,<4.0; 0.0.233 Requires-Python >=3.8.1,<4.0; 0.0.234 Requires-Python >=3.8.1,<4.0; 0.0.235 Requires-Python >=3.8.1,<4.0; 0.0.236 Requires-Python >=3.8.1,<4.0; 0.0.237 Requires-Python >=3.8.1,<4.0; 0.0.238 Requires-Python >=3.8.1,<4.0; 0.0.239 Requires-Python >=3.8.1,<4.0; 0.0.240 Requires-Python >=3.8.1,<4.0; 0.0.240rc0 Requires-Python >=3.8.1,<4.0; 0.0.240rc1 Requires-Python >=3.8.1,<4.0; 0.0.240rc4 Requires-Python >=3.8.1,<4.0; 0.0.242 Requires-Python >=3.8.1,<4.0; 0.0.243 Requires-Python >=3.8.1,<4.0; 0.0.244 Requires-Python >=3.8.1,<4.0; 0.0.245 Requires-Python >=3.8.1,<4.0; 0.0.246 Requires-Python >=3.8.1,<4.0; 0.0.247 Requires-Python >=3.8.1,<4.0; 0.0.248 Requires-Python >=3.8.1,<4.0; 0.0.249 Requires-Python >=3.8.1,<4.0; 0.0.250 Requires-Python >=3.8.1,<4.0; 0.0.251 Requires-Python >=3.8.1,<4.0; 0.0.252 Requires-Python >=3.8.1,<4.0; 0.0.253 Requires-Python >=3.8.1,<4.0; 0.0.254 Requires-Python >=3.8.1,<4.0; 0.0.255 Requires-Python >=3.8.1,<4.0; 0.0.256 Requires-Python >=3.8.1,<4.0; 0.0.257 Requires-Python >=3.8.1,<4.0; 0.0.258 Requires-Python >=3.8.1,<4.0; 0.0.259 Requires-Python >=3.8.1,<4.0; 0.0.260 Requires-Python >=3.8.1,<4.0; 0.0.261 Requires-Python >=3.8.1,<4.0; 0.0.262 Requires-Python >=3.8.1,<4.0; 0.0.263 Requires-Python >=3.8.1,<4.0; 0.0.264 Requires-Python >=3.8.1,<4.0; 0.0.265 Requires-Python >=3.8.1,<4.0; 0.0.266 Requires-Python >=3.8.1,<4.0; 0.0.267 Requires-Python >=3.8.1,<4.0; 0.0.268 Requires-Python >=3.8.1,<4.0; 0.0.269 Requires-Python >=3.8.1,<4.0; 0.0.270 Requires-Python >=3.8.1,<4.0; 0.0.271 Requires-Python >=3.8.1,<4.0; 0.0.272 Requires-Python >=3.8.1,<4.0; 0.0.273 Requires-Python >=3.8.1,<4.0; 0.0.274 Requires-Python >=3.8.1,<4.0; 0.0.275 Requires-Python >=3.8.1,<4.0; 0.0.276 Requires-Python >=3.8.1,<4.0; 0.0.277 Requires-Python >=3.8.1,<4.0; 0.0.278 Requires-Python >=3.8.1,<4.0; 0.0.279 Requires-Python >=3.8.1,<4.0; 0.0.28 Requires-Python >=3.8.1,<4.0; 0.0.281 Requires-Python >=3.8.1,<4.0; 0.0.283 Requires-Python >=3.8.1,<4.0; 0.0.284 Requires-Python >=3.8.1,<4.0; 0.0.285 Requires-Python >=3.8.1,<4.0; 0.0.286 Requires-Python >=3.8.1,<4.0; 0.0.287 Requires-Python >=3.8.1,<4.0; 0.0.288 Requires-Python >=3.8.1,<4.0; 0.0.289 Requires-Python >=3.8.1,<4.0; 0.0.29 Requires-Python >=3.8.1,<4.0; 0.0.290 Requires-Python >=3.8.1,<4.0; 0.0.291 Requires-Python >=3.8.1,<4.0; 0.0.292 Requires-Python >=3.8.1,<4.0; 0.0.293 Requires-Python >=3.8.1,<4.0; 0.0.294 Requires-Python >=3.8.1,<4.0; 0.0.295 Requires-Python >=3.8.1,<4.0; 0.0.296 Requires-Python >=3.8.1,<4.0; 0.0.297 Requires-Python >=3.8.1,<4.0; 0.0.298 Requires-Python >=3.8.1,<4.0; 0.0.299 Requires-Python >=3.8.1,<4.0; 0.0.30 Requires-Python >=3.8.1,<4.0; 0.0.300 Requires-Python >=3.8.1,<4.0; 0.0.301 Requires-Python >=3.8.1,<4.0; 0.0.302 Requires-Python >=3.8.1,<4.0; 0.0.303 Requires-Python >=3.8.1,<4.0; 0.0.304 Requires-Python >=3.8.1,<4.0; 0.0.305 Requires-Python >=3.8.1,<4.0; 0.0.306 Requires-Python >=3.8.1,<4.0; 0.0.307 Requires-Python >=3.8.1,<4.0; 0.0.308 Requires-Python >=3.8.1,<4.0; 0.0.309 Requires-Python >=3.8.1,<4.0; 0.0.31 Requires-Python >=3.8.1,<4.0; 0.0.310 Requires-Python >=3.8.1,<4.0; 0.0.311 Requires-Python >=3.8.1,<4.0; 0.0.312 Requires-Python >=3.8.1,<4.0; 0.0.313 Requires-Python >=3.8.1,<4.0; 0.0.314 Requires-Python >=3.8.1,<4.0; 0.0.315 Requires-Python >=3.8.1,<4.0; 0.0.316 Requires-Python >=3.8.1,<4.0; 0.0.317 Requires-Python >=3.8.1,<4.0; 0.0.318 Requires-Python >=3.8.1,<4.0; 0.0.319 Requires-Python >=3.8.1,<4.0; 0.0.32 Requires-Python >=3.8.1,<4.0; 0.0.320 Requires-Python >=3.8.1,<4.0; 0.0.321 Requires-Python >=3.8.1,<4.0; 0.0.322 Requires-Python >=3.8.1,<4.0; 0.0.323 Requires-Python >=3.8.1,<4.0; 0.0.324 Requires-Python >=3.8.1,<4.0; 0.0.325 Requires-Python >=3.8.1,<4.0; 0.0.326 Requires-Python >=3.8.1,<4.0; 0.0.327 Requires-Python >=3.8.1,<4.0; 0.0.329 Requires-Python >=3.8.1,<4.0; 0.0.33 Requires-Python >=3.8.1,<4.0; 0.0.330 Requires-Python >=3.8.1,<4.0; 0.0.331 Requires-Python >=3.8.1,<4.0; 0.0.331rc0 Requires-Python >=3.8.1,<4.0; 0.0.331rc1 Requires-Python >=3.8.1,<4.0; 0.0.331rc2 Requires-Python >=3.8.1,<4.0; 0.0.331rc3 Requires-Python >=3.8.1,<4.0; 0.0.332 Requires-Python >=3.8.1,<4.0; 0.0.333 Requires-Python >=3.8.1,<4.0; 0.0.334 Requires-Python >=3.8.1,<4.0; 0.0.335 Requires-Python >=3.8.1,<4.0; 0.0.336 Requires-Python >=3.8.1,<4.0; 0.0.337 Requires-Python >=3.8.1,<4.0; 0.0.338 Requires-Python >=3.8.1,<4.0; 0.0.339 Requires-Python >=3.8.1,<4.0; 0.0.339rc0 Requires-Python >=3.8.1,<4.0; 0.0.339rc1 Requires-Python >=3.8.1,<4.0; 0.0.339rc2 Requires-Python >=3.8.1,<4.0; 0.0.339rc3 Requires-Python >=3.8.1,<4.0; 0.0.34 Requires-Python >=3.8.1,<4.0; 0.0.340 Requires-Python >=3.8.1,<4.0; 0.0.341 Requires-Python >=3.8.1,<4.0; 0.0.342 Requires-Python >=3.8.1,<4.0; 0.0.343 Requires-Python >=3.8.1,<4.0; 0.0.344 Requires-Python >=3.8.1,<4.0; 0.0.35 Requires-Python >=3.8.1,<4.0; 0.0.36 Requires-Python >=3.8.1,<4.0; 0.0.37 Requires-Python >=3.8.1,<4.0; 0.0.38 Requires-Python >=3.8.1,<4.0; 0.0.39 Requires-Python >=3.8.1,<4.0; 0.0.40 Requires-Python >=3.8.1,<4.0; 0.0.41 Requires-Python >=3.8.1,<4.0; 0.0.42 Requires-Python >=3.8.1,<4.0; 0.0.43 Requires-Python >=3.8.1,<4.0; 0.0.44 Requires-Python >=3.8.1,<4.0; 0.0.45 Requires-Python >=3.8.1,<4.0; 0.0.46 Requires-Python >=3.8.1,<4.0; 0.0.47 Requires-Python >=3.8.1,<4.0; 0.0.48 Requires-Python >=3.8.1,<4.0; 0.0.49 Requires-Python >=3.8.1,<4.0; 0.0.50 Requires-Python >=3.8.1,<4.0; 0.0.51 Requires-Python >=3.8.1,<4.0; 0.0.52 Requires-Python >=3.8.1,<4.0; 0.0.53 Requires-Python >=3.8.1,<4.0; 0.0.54 Requires-Python >=3.8.1,<4.0; 0.0.55 Requires-Python >=3.8.1,<4.0; 0.0.56 Requires-Python >=3.8.1,<4.0; 0.0.57 Requires-Python >=3.8.1,<4.0; 0.0.58 Requires-Python >=3.8.1,<4.0; 0.0.59 Requires-Python >=3.8.1,<4.0; 0.0.60 Requires-Python >=3.8.1,<4.0; 0.0.61 Requires-Python >=3.8.1,<4.0; 0.0.63 Requires-Python >=3.8.1,<4.0; 0.0.64 Requires-Python >=3.8.1,<4.0; 0.0.65 Requires-Python >=3.8.1,<4.0; 0.0.66 Requires-Python >=3.8.1,<4.0; 0.0.67 Requires-Python >=3.8.1,<4.0; 0.0.68 Requires-Python >=3.8.1,<4.0; 0.0.69 Requires-Python >=3.8.1,<4.0; 0.0.70 Requires-Python >=3.8.1,<4.0; 0.0.71 Requires-Python >=3.8.1,<4.0; 0.0.72 Requires-Python >=3.8.1,<4.0; 0.0.73 Requires-Python >=3.8.1,<4.0; 0.0.74 Requires-Python >=3.8.1,<4.0; 0.0.75 Requires-Python >=3.8.1,<4.0; 0.0.76 Requires-Python >=3.8.1,<4.0; 0.0.77 Requires-Python >=3.8.1,<4.0; 0.0.78 Requires-Python >=3.8.1,<4.0; 0.0.79 Requires-Python >=3.8.1,<4.0; 0.0.80 Requires-Python >=3.8.1,<4.0; 0.0.81 Requires-Python >=3.8.1,<4.0; 0.0.82 Requires-Python >=3.8.1,<4.0; 0.0.83 Requires-Python >=3.8.1,<4.0; 0.0.84 Requires-Python >=3.8.1,<4.0; 0.0.85 Requires-Python >=3.8.1,<4.0; 0.0.86 Requires-Python >=3.8.1,<4.0; 0.0.87 Requires-Python >=3.8.1,<4.0; 0.0.88 Requires-Python >=3.8.1,<4.0; 0.0.89 Requires-Python >=3.8.1,<4.0; 0.0.90 Requires-Python >=3.8.1,<4.0; 0.0.91 Requires-Python >=3.8.1,<4.0; 0.0.92 Requires-Python >=3.8.1,<4.0; 0.0.93 Requires-Python >=3.8.1,<4.0; 0.0.94 Requires-Python >=3.8.1,<4.0; 0.0.95 Requires-Python >=3.8.1,<4.0; 0.0.96 Requires-Python >=3.8.1,<4.0; 0.0.97 Requires-Python >=3.8.1,<4.0; 0.0.98 Requires-Python >=3.8.1,<4.0; 0.0.99 Requires-Python >=3.8.1,<4.0; 0.0.99rc0 Requires-Python >=3.8.1,<4.0; 0.1.1 Requires-Python >=3.9; 0.8.43 Requires-Python >=3.8.1,<3.12; 0.8.43.post1 Requires-Python >=3.8.1,<3.12; 0.8.44 Requires-Python >=3.8.1,<3.12; 0.8.45 Requires-Python >=3.8.1,<3.12; 0.8.45.post1 Requires-Python >=3.8.1,<3.12; 0.8.46 Requires-Python >=3.8.1,<3.12; 0.8.47 Requires-Python >=3.8.1,<3.12; 0.8.48 Requires-Python >=3.8.1,<3.12; 0.8.49 Requires-Python >=3.8.1,<3.12; 0.8.50 Requires-Python >=3.8.1,<3.12; 0.8.51 Requires-Python >=3.8.1,<3.12; 0.8.51.post1 Requires-Python >=3.8.1,<3.12; 0.8.52 Requires-Python >=3.8.1,<3.12; 0.8.53 Requires-Python >=3.8.1,<3.12; 0.8.53.post3 Requires-Python >=3.8.1,<3.12; 0.8.54 Requires-Python >=3.8.1,<3.12; 0.8.55 Requires-Python >=3.8.1,<3.12; 0.8.56 Requires-Python >=3.8.1,<3.12; 0.8.57 Requires-Python >=3.8.1,<3.12; 0.8.58 Requires-Python >=3.8.1,<3.12; 0.8.59 Requires-Python >=3.8.1,<3.12; 0.8.61 Requires-Python >=3.8.1,<3.12; 0.8.62 Requires-Python >=3.8.1,<3.12; 0.8.63.post1 Requires-Python >=3.8.1,<3.12; 0.8.63.post2 Requires-Python >=3.8.1,<3.12; 0.8.64 Requires-Python >=3.8.1,<3.12; 0.8.64.post1 Requires-Python >=3.8.1,<3.12; 0.8.65 Requires-Python >=3.8.1,<3.12; 0.8.66 Requires-Python >=3.8.1,<3.12; 0.8.67 Requires-Python >=3.8.1,<3.12; 0.8.68 Requires-Python >=3.8.1,<3.12; 0.8.69 Requires-Python >=3.8.1,<3.12; 0.8.69.post1 Requires-Python >=3.8.1,<3.12; 0.8.69.post2 Requires-Python >=3.8.1,<3.12; 0.9.0 Requires-Python >=3.8.1,<3.12; 0.9.0.post1 Requires-Python >=3.8.1,<3.12; 0.9.0a1 Requires-Python >=3.8.1,<3.12; 0.9.0a2 Requires-Python >=3.8.1,<3.12; 0.9.0a3 Requires-Python >=3.8.1,<3.12; 0.9.1 Requires-Python >=3.8.1,<3.12; 0.9.10 Requires-Python >=3.8.1,<3.12; 0.9.10a1 Requires-Python >=3.8.1,<3.12; 0.9.10a2 Requires-Python >=3.8.1,<3.12; 0.9.2 Requires-Python >=3.8.1,<3.12; 0.9.3 Requires-Python >=3.8.1,<3.12; 0.9.3.post1 Requires-Python >=3.8.1,<3.12; 0.9.4 Requires-Python >=3.8.1,<3.12; 0.9.5 Requires-Python >=3.8.1,<3.12; 0.9.6 Requires-Python >=3.8.1,<3.12; 0.9.6.post1 Requires-Python >=3.8.1,<3.12; 0.9.6.post2 Requires-Python >=3.8.1,<3.12; 0.9.7 Requires-Python >=3.8.1,<3.12; 0.9.8 Requires-Python >=3.8.1,<3.12; 0.9.8.post1 Requires-Python >=3.8.1,<3.12; 0.9.9 Requires-Python >=3.8.1,<3.12\n",
      "ERROR: Could not find a version that satisfies the requirement langchain>=0.0.262 (from llama-index) (from versions: 0.0.1, 0.0.2, 0.0.3, 0.0.4, 0.0.5, 0.0.6, 0.0.7, 0.0.8, 0.0.9, 0.0.10, 0.0.11, 0.0.12, 0.0.13, 0.0.14, 0.0.15, 0.0.16, 0.0.17, 0.0.18, 0.0.19, 0.0.20, 0.0.21, 0.0.22, 0.0.23, 0.0.24, 0.0.25, 0.0.26, 0.0.27)\n",
      "ERROR: No matching distribution found for langchain>=0.0.262\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca48bd0f03e6da91",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Load Training Data for Finetuning LLaMa\n",
    "\n",
    "We load data from `b-mc2/sql-create-context` on Hugging Face: https://huggingface.co/datasets/b-mc2/sql-create-context.\n",
    "\n",
    "This dataset consists of tuples of natural language queries, create table statements, and ground-truth SQL queries. This is the dataset that we use to finetune our SQL model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3130637072fdba2c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-02T06:43:57.525728200Z"
    },
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_dir = \"data_sql\"\n",
    "\n",
    "!modal run src.load_data_sql --data-dir {data_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504083566cf863ff",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Run Finetuning Script\n",
    "\n",
    "We run our finetuning script on the loaded dataset.\n",
    "The finetuning script contains the following components:\n",
    "- We split the dataset into training and validation splits.\n",
    "- We format each split into input/output tuples of token id's. This means that the labels are the same as inputs (loss signal is measured on full input, not just on the generated portion).\n",
    "- We use `LoraConfig` from `peft` for efficient fine-tuning.\n",
    "- We use `transformers.Trainer` to actually run the training process.\n",
    "- If a valid `WANDB_PROJECT` is specified, along with the relevant secret in Modal, then we will log results to wandb.\n",
    "\n",
    "We use Modal to spin up an A100 to run our finetuning code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73b0775c25a57687",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"data_sql\"\n",
    "\n",
    "!modal run src.finetune_sql --data-dir {data_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8cf0faea68f649",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Evaluation\n",
    "\n",
    "We provide a basic evaluation script over sample data from `sql-create-context` so that you can see for yourself how well the finetuned model performs vs. the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5f532fb51fa3976",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T03:59:28.925893700Z",
     "start_time": "2023-12-02T03:59:28.807721700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+--------------------- Traceback (most recent call last) ---------------------+\n",
      "| D:\\python\\lib\\runpy.py:192 in _run_module_as_main                           |\n",
      "|                                                                             |\n",
      "|   191         sys.argv[0] = mod_spec.origin                                 |\n",
      "| > 192     return _run_code(code, main_globals, None,                        |\n",
      "|   193                      \"__main__\", mod_spec)                            |\n",
      "|                                                                             |\n",
      "| D:\\python\\lib\\runpy.py:85 in _run_code                                      |\n",
      "|                                                                             |\n",
      "|    84                        __spec__ = mod_spec)                           |\n",
      "| >  85     exec(code, run_globals)                                           |\n",
      "|    86     return run_globals                                                |\n",
      "|                                                                             |\n",
      "| D:\\python\\Scripts\\modal.exe\\__main__.py:7 in <module>                       |\n",
      "|                                                                             |\n",
      "|                                                                             |\n",
      "| D:\\python\\lib\\site-packages\\modal\\__main__.py:9 in main                     |\n",
      "|                                                                             |\n",
      "|    8     setup_rich_traceback()                                             |\n",
      "| >  9     entrypoint_cli()                                                   |\n",
      "|   10                                                                        |\n",
      "|                                                                             |\n",
      "| D:\\python\\lib\\site-packages\\click\\core.py:1157 in __call__                  |\n",
      "|                                                                             |\n",
      "|   1156         \"\"\"Alias for :meth:`main`.\"\"\"                                |\n",
      "| > 1157         return self.main(*args, **kwargs)                            |\n",
      "|   1158                                                                      |\n",
      "|                                                                             |\n",
      "| D:\\python\\lib\\site-packages\\typer\\core.py:778 in main                       |\n",
      "|                                                                             |\n",
      "|   777     ) -> Any:                                                         |\n",
      "| > 778         return _main(                                                 |\n",
      "|   779             self,                                                     |\n",
      "|                                                                             |\n",
      "| D:\\python\\lib\\site-packages\\typer\\core.py:216 in _main                      |\n",
      "|                                                                             |\n",
      "|   215             with self.make_context(prog_name, args, **extra) as ctx:  |\n",
      "| > 216                 rv = self.invoke(ctx)                                 |\n",
      "|   217                 if not standalone_mode:                               |\n",
      "|                                                                             |\n",
      "| D:\\python\\lib\\site-packages\\click\\core.py:1688 in invoke                    |\n",
      "|                                                                             |\n",
      "|   1687                 with sub_ctx:                                        |\n",
      "| > 1688                     return _process_result(sub_ctx.command.invoke(su |\n",
      "|   1689                                                                      |\n",
      "|                                                                             |\n",
      "| D:\\python\\lib\\site-packages\\click\\core.py:1682 in invoke                    |\n",
      "|                                                                             |\n",
      "|   1681             with ctx:                                                |\n",
      "| > 1682                 cmd_name, cmd, args = self.resolve_command(ctx, args |\n",
      "|   1683                 assert cmd is not None                               |\n",
      "|                                                                             |\n",
      "| D:\\python\\lib\\site-packages\\click\\core.py:1729 in resolve_command           |\n",
      "|                                                                             |\n",
      "|   1728         # Get the command                                            |\n",
      "| > 1729         cmd = self.get_command(ctx, cmd_name)                        |\n",
      "|   1730                                                                      |\n",
      "|                                                                             |\n",
      "| D:\\python\\lib\\site-packages\\modal\\cli\\run.py:162 in get_command             |\n",
      "|                                                                             |\n",
      "|   161     def get_command(self, ctx, func_ref):                             |\n",
      "| > 162         function_or_entrypoint = import_function(func_ref, accept_loc |\n",
      "|   163         stub: Stub = function_or_entrypoint.stub                      |\n",
      "|                                                                             |\n",
      "| D:\\python\\lib\\site-packages\\modal\\cli\\import_refs.py:227 in import_function |\n",
      "|                                                                             |\n",
      "|   226     try:                                                              |\n",
      "| > 227         module = import_file_or_module(import_ref.file_or_module)     |\n",
      "|   228         obj_path = import_ref.object_path or DEFAULT_STUB_NAME  # get |\n",
      "|                                                                             |\n",
      "| D:\\python\\lib\\site-packages\\modal\\cli\\import_refs.py:77 in                  |\n",
      "| import_file_or_module                                                       |\n",
      "|                                                                             |\n",
      "|    76     else:                                                             |\n",
      "| >  77         module = importlib.import_module(file_or_module)              |\n",
      "|    78                                                                       |\n",
      "|                                                                             |\n",
      "| D:\\python\\lib\\importlib\\__init__.py:127 in import_module                    |\n",
      "|                                                                             |\n",
      "|   126             level += 1                                                |\n",
      "| > 127     return _bootstrap._gcd_import(name[level:], package, level)       |\n",
      "|   128                                                                       |\n",
      "| <frozen importlib._bootstrap>:1014 in _gcd_import                           |\n",
      "|                                                                             |\n",
      "| <frozen importlib._bootstrap>:991 in _find_and_load                         |\n",
      "|                                                                             |\n",
      "| <frozen importlib._bootstrap>:975 in _find_and_load_unlocked                |\n",
      "|                                                                             |\n",
      "| <frozen importlib._bootstrap>:671 in _load_unlocked                         |\n",
      "|                                                                             |\n",
      "| <frozen importlib._bootstrap_external>:783 in exec_module                   |\n",
      "|                                                                             |\n",
      "| <frozen importlib._bootstrap>:219 in _call_with_frames_removed              |\n",
      "|                                                                             |\n",
      "|                                                                             |\n",
      "| C:\\Users\\汽车\\Desktop\\hugging_face_test\\demo\\test_nlq_to_sql\\modal_finetune |\n",
      "| _sql\\src\\eval_sql.py:10 in <module>                                         |\n",
      "|                                                                             |\n",
      "|     9 )                                                                     |\n",
      "| >  10 from .inference_utils import OpenLlamaLLM                             |\n",
      "|    11                                                                       |\n",
      "|                                                                             |\n",
      "| C:\\Users\\汽车\\Desktop\\hugging_face_test\\demo\\test_nlq_to_sql\\modal_finetune |\n",
      "| _sql\\src\\inference_utils.py:16 in <module>                                  |\n",
      "|                                                                             |\n",
      "|    15                                                                       |\n",
      "| >  16 from llama_index.callbacks import CallbackManager                     |\n",
      "|    17 from llama_index.llms import (                                        |\n",
      "|                                                                             |\n",
      "| D:\\python\\lib\\site-packages\\llama_index\\__init__.py:14 in <module>          |\n",
      "|                                                                             |\n",
      "|    13 # embeddings                                                          |\n",
      "| >  14 from llama_index.embeddings.langchain import LangchainEmbedding       |\n",
      "|    15 from llama_index.embeddings.openai import OpenAIEmbedding             |\n",
      "|                                                                             |\n",
      "| D:\\python\\lib\\site-packages\\llama_index\\embeddings\\langchain.py:6 in        |\n",
      "| <module>                                                                    |\n",
      "|                                                                             |\n",
      "|    5                                                                        |\n",
      "| >  6 from langchain.embeddings.base import Embeddings as LCEmbeddings       |\n",
      "|    7                                                                        |\n",
      "|                                                                             |\n",
      "| D:\\python\\lib\\site-packages\\langchain\\__init__.py:8 in <module>             |\n",
      "|                                                                             |\n",
      "|    7                                                                        |\n",
      "| >  8 from langchain.agents import MRKLChain, ReActChain, SelfAskWithSearchC |\n",
      "|    9 from langchain.chains import (                                         |\n",
      "|                                                                             |\n",
      "| D:\\python\\lib\\site-packages\\langchain\\agents\\__init__.py:2 in <module>      |\n",
      "|                                                                             |\n",
      "|    1 \"\"\"Routing chains.\"\"\"                                                  |\n",
      "| >  2 from langchain.agents.agent import Agent                               |\n",
      "|    3 from langchain.agents.loading import initialize_agent                  |\n",
      "|                                                                             |\n",
      "| D:\\python\\lib\\site-packages\\langchain\\agents\\agent.py:10 in <module>        |\n",
      "|                                                                             |\n",
      "|     9 from langchain.agents.tools import Tool                               |\n",
      "| >  10 from langchain.chains.base import Chain                               |\n",
      "|    11 from langchain.chains.llm import LLMChain                             |\n",
      "|                                                                             |\n",
      "| D:\\python\\lib\\site-packages\\langchain\\chains\\__init__.py:2 in <module>      |\n",
      "|                                                                             |\n",
      "|    1 \"\"\"Chains are easily reusable components which can be linked together. |\n",
      "| >  2 from langchain.chains.conversation.base import ConversationChain       |\n",
      "|    3 from langchain.chains.llm import LLMChain                              |\n",
      "|                                                                             |\n",
      "| D:\\python\\lib\\site-packages\\langchain\\chains\\conversation\\base.py:7 in      |\n",
      "| <module>                                                                    |\n",
      "|                                                                             |\n",
      "|    6 from langchain.chains.base import Memory                               |\n",
      "| >  7 from langchain.chains.conversation.memory import ConversationBufferMem |\n",
      "|    8 from langchain.chains.conversation.prompt import PROMPT                |\n",
      "|                                                                             |\n",
      "| D:\\python\\lib\\site-packages\\langchain\\chains\\conversation\\memory.py:7 in    |\n",
      "| <module>                                                                    |\n",
      "|                                                                             |\n",
      "|    6 from langchain.chains.base import Memory                               |\n",
      "| >  7 from langchain.chains.conversation.prompt import SUMMARY_PROMPT        |\n",
      "|    8 from langchain.chains.llm import LLMChain                              |\n",
      "|                                                                             |\n",
      "| D:\\python\\lib\\site-packages\\langchain\\chains\\conversation\\prompt.py:2 in    |\n",
      "| <module>                                                                    |\n",
      "|                                                                             |\n",
      "|    1 # flake8: noqa                                                         |\n",
      "| >  2 from langchain.prompts.prompt import PromptTemplate                    |\n",
      "|    3                                                                        |\n",
      "|                                                                             |\n",
      "| D:\\python\\lib\\site-packages\\langchain\\prompts\\__init__.py:2 in <module>     |\n",
      "|                                                                             |\n",
      "|    1 \"\"\"Prompt template classes.\"\"\"                                         |\n",
      "| >  2 from langchain.prompts.base import BasePromptTemplate                  |\n",
      "|    3 from langchain.prompts.few_shot import FewShotPromptTemplate           |\n",
      "|                                                                             |\n",
      "| D:\\python\\lib\\site-packages\\langchain\\prompts\\base.py:35 in <module>        |\n",
      "|                                                                             |\n",
      "|    34                                                                       |\n",
      "| >  35 class BasePromptTemplate(BaseModel, ABC):                             |\n",
      "|    36     \"\"\"Base prompt should expose the format method, returning a promp |\n",
      "|                                                                             |\n",
      "| D:\\python\\lib\\site-packages\\langchain\\prompts\\base.py:41 in                 |\n",
      "| BasePromptTemplate                                                          |\n",
      "|                                                                             |\n",
      "|    40                                                                       |\n",
      "| >  41     @root_validator()                                                 |\n",
      "|    42     def validate_variable_names(cls, values: Dict) -> Dict:           |\n",
      "|                                                                             |\n",
      "| D:\\python\\lib\\site-packages\\pydantic\\deprecated\\class_validators.py:237 in  |\n",
      "| root_validator                                                              |\n",
      "|                                                                             |\n",
      "|   236     if pre is False and skip_on_failure is not True:                  |\n",
      "| > 237         raise PydanticUserError(                                      |\n",
      "|   238             'If you use `@root_validator` with pre=False (the default |\n",
      "+-----------------------------------------------------------------------------+\n",
      "PydanticUserError: If you use `@root_validator` with pre=False (the default) \n",
      "you MUST specify `skip_on_failure=True`. Note that `@root_validator` is \n",
      "deprecated and should be replaced with `@model_validator`.\n",
      "\n",
      "For further information visit \n",
      "https://errors.pydantic.dev/2.5/u/root-validator-pre-skip\n"
     ]
    }
   ],
   "source": [
    "!modal run src.eval_sql::main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa5f314a6921d3b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Integrate Model with LlamaIndex\n",
    "\n",
    "Now that the model is finetuned, the checkpoints and model binary are stored in a model directory (by default it is in `/vol/data_sql`).\n",
    "\n",
    "We can now use this model in LlamaIndex for text-to-SQL applications.\n",
    "\n",
    "Specifically, we provide an interface allowing users to define any `sqlite` data file, and then they can run queries over this data file. We first create and dump a sample `cities.db` file containing (city, population, country) tuples. We then run inference over this file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19abfbf240fe826a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Create sample db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f898289657fbc462",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# create sample\n",
    "from sqlalchemy import (\n",
    "    create_engine,\n",
    "    MetaData,\n",
    "    Table,\n",
    "    Column,\n",
    "    String,\n",
    "    Integer,\n",
    "    select,\n",
    "    column,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a053c025891a1a9e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "db_file = \"cities.db\"\n",
    "engine = create_engine(f\"sqlite:///{db_file}\")\n",
    "metadata_obj = MetaData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27a2cd57dd77783",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# create city SQL table\n",
    "table_name = \"city_stats\"\n",
    "city_stats_table = Table(\n",
    "    table_name,\n",
    "    metadata_obj,\n",
    "    Column(\"city_name\", String(16), primary_key=True),\n",
    "    Column(\"population\", Integer),\n",
    "    Column(\"country\", String(16), nullable=False),\n",
    ")\n",
    "metadata_obj.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a73f631f2a16ff",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# insert sample rows\n",
    "from sqlalchemy import insert\n",
    "\n",
    "rows = [\n",
    "    {\"city_name\": \"多伦多\", \"population\": 2930000, \"country\": \"加拿大\"},\n",
    "    {\"city_name\": \"东京\", \"population\": 13960000, \"country\": \"日本\"},\n",
    "    {\"city_name\": \"芝加哥\", \"population\": 2679000, \"country\": \"美国\"},\n",
    "    {\"city_name\": \"首尔\", \"population\": 9776000, \"country\": \"韩国\"},\n",
    "]\n",
    "for row in rows:\n",
    "    stmt = insert(city_stats_table).values(**row)\n",
    "    with engine.connect() as connection:\n",
    "        cursor = connection.execute(stmt)\n",
    "        connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23645e518f25194",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3cad7f1ad0c9d0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "query = \"哪个城市的人口最多?\"\n",
    "\n",
    "!modal run src.inference_sql_llamaindex::main --query '{query}' --sqlite-file-path {db_file} --model-dir \"data_sql\" --use-finetuned-model True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6307bfd88ea8ea91",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# you can also choose to run the original (nonfinetuned model) to compare results\n",
    "# note: it throws an error\n",
    "\n",
    "# use non-finetuned model\n",
    "!modal run src.inference_sql_llamaindex::main --query '{query}' --sqlite-file-path {db_file} --model-dir \"data_sql\" --use-finetuned-model False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f03fff861e4f85c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### (Optional) Download Model\n",
    "\n",
    "If you want to download the model weights for your own use, just run the following script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad7a136a36600ec",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from src.download_weights import main\n",
    "\n",
    "main(\"out_model\", model_dir=\"data_sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89579dd4e6def74e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import Repository\n",
    "\n",
    "def upload_model_to_huggingface(model_dir: str, model_id: str):\n",
    "    repo = Repository(local_dir=model_dir, clone_from=model_id)\n",
    "    repo.push_to_hub()\n",
    "\n",
    "# 使用您的 Hugging Face 用户名和模型名称替换 \"your-username/your-model-name\"\n",
    "upload_model_to_huggingface(\"data_sql\", \"jtjt520j/test_atom_7B_text_to_sql\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
