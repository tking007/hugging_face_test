{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CHIeRg3BQN2k",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4fe8558a-3cb5-4e5d-8aa0-c5aee27e84f5"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'test_llama_board'...\n",
      "remote: Enumerating objects: 166, done.\u001B[K\n",
      "remote: Counting objects: 100% (7/7), done.\u001B[K\n",
      "remote: Compressing objects: 100% (5/5), done.\u001B[K\n",
      "remote: Total 166 (delta 0), reused 4 (delta 0), pack-reused 159\u001B[K\n",
      "Receiving objects: 100% (166/166), 79.06 MiB | 10.30 MiB/s, done.\n",
      "Resolving deltas: 100% (12/12), done.\n",
      "Updating files: 100% (129/129), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/tking007/test_llama_board.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y9fGod8_Qgjg",
    "outputId": "be97e8b3-2e1b-4576-ebdf-50c444429f6a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content\n",
      "/content/test_llama_board\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.getcwd())# 显示当前工作路径\n",
    "\n",
    "os.chdir('/content/test_llama_board')  # 切换当前工作路径\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "aFqg38DWRaq5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "57963bdb-253a-43ab-b61c-650944506a17"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.1.0+cu121)\n",
      "Collecting transformers>=4.36.0 (from -r requirements.txt (line 2))\n",
      "  Downloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m8.2/8.2 MB\u001B[0m \u001B[31m31.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting datasets>=2.14.3 (from -r requirements.txt (line 3))\n",
      "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m521.2/521.2 kB\u001B[0m \u001B[31m38.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting accelerate>=0.21.0 (from -r requirements.txt (line 4))\n",
      "  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m265.7/265.7 kB\u001B[0m \u001B[31m33.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting peft>=0.7.0 (from -r requirements.txt (line 5))\n",
      "  Downloading peft-0.7.1-py3-none-any.whl (168 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m168.3/168.3 kB\u001B[0m \u001B[31m23.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting trl>=0.7.4 (from -r requirements.txt (line 6))\n",
      "  Downloading trl-0.7.4-py3-none-any.whl (133 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m133.9/133.9 kB\u001B[0m \u001B[31m18.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting gradio<4.0.0,>=3.38.0 (from -r requirements.txt (line 7))\n",
      "  Downloading gradio-3.50.2-py3-none-any.whl (20.3 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m20.3/20.3 MB\u001B[0m \u001B[31m65.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (1.11.4)\n",
      "Collecting sentencepiece (from -r requirements.txt (line 9))\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.3/1.3 MB\u001B[0m \u001B[31m78.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (3.20.3)\n",
      "Collecting tiktoken (from -r requirements.txt (line 11))\n",
      "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.0/2.0 MB\u001B[0m \u001B[31m89.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (0.42.1)\n",
      "Collecting rouge-chinese (from -r requirements.txt (line 13))\n",
      "  Downloading rouge_chinese-1.0.3-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (3.8.1)\n",
      "Collecting uvicorn (from -r requirements.txt (line 15))\n",
      "  Downloading uvicorn-0.25.0-py3-none-any.whl (60 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m60.3/60.3 kB\u001B[0m \u001B[31m9.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (1.10.13)\n",
      "Collecting fastapi (from -r requirements.txt (line 17))\n",
      "  Downloading fastapi-0.105.0-py3-none-any.whl (93 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m93.1/93.1 kB\u001B[0m \u001B[31m6.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting sse-starlette (from -r requirements.txt (line 18))\n",
      "  Downloading sse_starlette-1.8.2-py3-none-any.whl (8.9 kB)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (3.7.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 2)) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 2)) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 2)) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 2)) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 2)) (2023.6.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 2)) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 2)) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 2)) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 2)) (4.66.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->-r requirements.txt (line 3)) (10.0.1)\n",
      "Collecting pyarrow-hotfix (from datasets>=2.14.3->-r requirements.txt (line 3))\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Collecting dill<0.3.8,>=0.3.0 (from datasets>=2.14.3->-r requirements.txt (line 3))\n",
      "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m115.3/115.3 kB\u001B[0m \u001B[31m16.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->-r requirements.txt (line 3)) (1.5.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->-r requirements.txt (line 3)) (3.4.1)\n",
      "Collecting multiprocess (from datasets>=2.14.3->-r requirements.txt (line 3))\n",
      "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m134.8/134.8 kB\u001B[0m \u001B[31m19.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->-r requirements.txt (line 3)) (3.9.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->-r requirements.txt (line 4)) (5.9.5)\n",
      "Collecting tyro>=0.5.11 (from trl>=0.7.4->-r requirements.txt (line 6))\n",
      "  Downloading tyro-0.6.1-py3-none-any.whl (78 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m78.5/78.5 kB\u001B[0m \u001B[31m11.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting aiofiles<24.0,>=22.0 (from gradio<4.0.0,>=3.38.0->-r requirements.txt (line 7))\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio<4.0.0,>=3.38.0->-r requirements.txt (line 7)) (4.2.2)\n",
      "Collecting ffmpy (from gradio<4.0.0,>=3.38.0->-r requirements.txt (line 7))\n",
      "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Collecting gradio-client==0.6.1 (from gradio<4.0.0,>=3.38.0->-r requirements.txt (line 7))\n",
      "  Downloading gradio_client-0.6.1-py3-none-any.whl (299 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m299.2/299.2 kB\u001B[0m \u001B[31m34.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting httpx (from gradio<4.0.0,>=3.38.0->-r requirements.txt (line 7))\n",
      "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m75.9/75.9 kB\u001B[0m \u001B[31m11.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio<4.0.0,>=3.38.0->-r requirements.txt (line 7)) (6.1.1)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio<4.0.0,>=3.38.0->-r requirements.txt (line 7)) (2.1.3)\n",
      "Collecting orjson~=3.0 (from gradio<4.0.0,>=3.38.0->-r requirements.txt (line 7))\n",
      "  Downloading orjson-3.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m138.7/138.7 kB\u001B[0m \u001B[31m299.3 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio<4.0.0,>=3.38.0->-r requirements.txt (line 7)) (9.4.0)\n",
      "Collecting pydub (from gradio<4.0.0,>=3.38.0->-r requirements.txt (line 7))\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting python-multipart (from gradio<4.0.0,>=3.38.0->-r requirements.txt (line 7))\n",
      "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m45.7/45.7 kB\u001B[0m \u001B[31m7.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting semantic-version~=2.0 (from gradio<4.0.0,>=3.38.0->-r requirements.txt (line 7))\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting websockets<12.0,>=10.0 (from gradio<4.0.0,>=3.38.0->-r requirements.txt (line 7))\n",
      "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m129.9/129.9 kB\u001B[0m \u001B[31m18.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge-chinese->-r requirements.txt (line 13)) (1.16.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->-r requirements.txt (line 14)) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->-r requirements.txt (line 14)) (1.3.2)\n",
      "Collecting h11>=0.8 (from uvicorn->-r requirements.txt (line 15))\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m58.3/58.3 kB\u001B[0m \u001B[31m9.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->-r requirements.txt (line 17)) (3.7.1)\n",
      "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->-r requirements.txt (line 17))\n",
      "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m67.0/67.0 kB\u001B[0m \u001B[31m9.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting typing-extensions (from torch>=1.13.1->-r requirements.txt (line 1))\n",
      "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 19)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 19)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 19)) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 19)) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 19)) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 19)) (2.8.2)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio<4.0.0,>=3.38.0->-r requirements.txt (line 7)) (0.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio<4.0.0,>=3.38.0->-r requirements.txt (line 7)) (4.19.2)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio<4.0.0,>=3.38.0->-r requirements.txt (line 7)) (0.12.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->-r requirements.txt (line 17)) (3.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->-r requirements.txt (line 17)) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->-r requirements.txt (line 17)) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.3->-r requirements.txt (line 3)) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.3->-r requirements.txt (line 3)) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.3->-r requirements.txt (line 3)) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.3->-r requirements.txt (line 3)) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.3->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.3->-r requirements.txt (line 3)) (4.0.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.14.3->-r requirements.txt (line 3)) (2023.3.post1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.36.0->-r requirements.txt (line 2)) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.36.0->-r requirements.txt (line 2)) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.36.0->-r requirements.txt (line 2)) (2023.11.17)\n",
      "Collecting docstring-parser>=0.14.1 (from tyro>=0.5.11->trl>=0.7.4->-r requirements.txt (line 6))\n",
      "  Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl>=0.7.4->-r requirements.txt (line 6)) (13.7.0)\n",
      "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl>=0.7.4->-r requirements.txt (line 6))\n",
      "  Downloading shtab-1.6.5-py3-none-any.whl (13 kB)\n",
      "Collecting httpcore==1.* (from httpx->gradio<4.0.0,>=3.38.0->-r requirements.txt (line 7))\n",
      "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m76.9/76.9 kB\u001B[0m \u001B[31m10.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.1->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio<4.0.0,>=3.38.0->-r requirements.txt (line 7)) (2023.11.2)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio<4.0.0,>=3.38.0->-r requirements.txt (line 7)) (0.32.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio<4.0.0,>=3.38.0->-r requirements.txt (line 7)) (0.15.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl>=0.7.4->-r requirements.txt (line 6)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl>=0.7.4->-r requirements.txt (line 6)) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl>=0.7.4->-r requirements.txt (line 6)) (0.1.2)\n",
      "Building wheels for collected packages: ffmpy\n",
      "  Building wheel for ffmpy (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=6a53990a5eda72a2a06fcffe6038c9ec5e01a74d172920b896f403e586633c5b\n",
      "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n",
      "Successfully built ffmpy\n",
      "Installing collected packages: sentencepiece, pydub, ffmpy, websockets, typing-extensions, shtab, semantic-version, rouge-chinese, python-multipart, pyarrow-hotfix, orjson, h11, docstring-parser, dill, aiofiles, uvicorn, tiktoken, starlette, multiprocess, httpcore, tyro, httpx, fastapi, accelerate, transformers, sse-starlette, gradio-client, datasets, trl, peft, gradio\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.5.0\n",
      "    Uninstalling typing_extensions-4.5.0:\n",
      "      Successfully uninstalled typing_extensions-4.5.0\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.35.2\n",
      "    Uninstalling transformers-4.35.2:\n",
      "      Successfully uninstalled transformers-4.35.2\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "lida 0.0.10 requires kaleido, which is not installed.\n",
      "llmx 0.0.15a0 requires cohere, which is not installed.\n",
      "llmx 0.0.15a0 requires openai, which is not installed.\n",
      "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0mSuccessfully installed accelerate-0.25.0 aiofiles-23.2.1 datasets-2.15.0 dill-0.3.7 docstring-parser-0.15 fastapi-0.105.0 ffmpy-0.3.1 gradio-3.50.2 gradio-client-0.6.1 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 multiprocess-0.70.15 orjson-3.9.10 peft-0.7.1 pyarrow-hotfix-0.6 pydub-0.25.1 python-multipart-0.0.6 rouge-chinese-1.0.3 semantic-version-2.10.0 sentencepiece-0.1.99 shtab-1.6.5 sse-starlette-1.8.2 starlette-0.27.0 tiktoken-0.5.2 transformers-4.36.2 trl-0.7.4 typing-extensions-4.9.0 tyro-0.6.1 uvicorn-0.25.0 websockets-11.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install einops transformers_stream_generator"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aNybn-DJYGgZ",
    "outputId": "e6852e94-9d9f-4d73-dafe-ff750b812e00"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting einops\n",
      "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/44.6 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m44.6/44.6 kB\u001B[0m \u001B[31m1.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting transformers_stream_generator\n",
      "  Downloading transformers-stream-generator-0.0.4.tar.gz (12 kB)\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Requirement already satisfied: transformers>=4.26.1 in /usr/local/lib/python3.10/dist-packages (from transformers_stream_generator) (4.36.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (2023.6.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers>=4.26.1->transformers_stream_generator) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers>=4.26.1->transformers_stream_generator) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (2023.11.17)\n",
      "Building wheels for collected packages: transformers_stream_generator\n",
      "  Building wheel for transformers_stream_generator (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for transformers_stream_generator: filename=transformers_stream_generator-0.0.4-py3-none-any.whl size=12316 sha256=254ab032b5ef12e7f9de977bc7f74d3ee661bc21d6cb90324cc3c49e6417fde4\n",
      "  Stored in directory: /root/.cache/pip/wheels/47/1d/3c/92d88493ed40c0d9be60a391eb76c9a56e9f9b7542cb789401\n",
      "Successfully built transformers_stream_generator\n",
      "Installing collected packages: einops, transformers_stream_generator\n",
      "Successfully installed einops-0.7.0 transformers_stream_generator-0.0.4\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python src/train_web.py"
   ],
   "metadata": {
    "id": "Gvaf9Z8iUUn0",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d69e5529-4e27-4e7b-8374-4226c1b8ef37"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2023-12-22 12:28:28.661999: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-22 12:28:28.662055: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-22 12:28:28.664053: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-22 12:28:29.892936: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n",
      "Running on local URL:  http://0.0.0.0:7860\n",
      "Running on public URL: https://3371654f4332d5bcbc.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
      "12/22/2023 12:31:03 - WARNING - llmtuner.model.parser - `ddp_find_unused_parameters` needs to be set as False for LoRA in DDP training.\n",
      "[INFO|training_args.py:1838] 2023-12-22 12:31:03,956 >> PyTorch: setting up devices\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1751: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of 🤗 Transformers. Use `--hub_token` instead.\n",
      "  warnings.warn(\n",
      "12/22/2023 12:31:03 - INFO - llmtuner.model.parser - Process rank: 0, device: cuda:0, n_gpu: 1\n",
      "  distributed training: True, compute dtype: torch.float16\n",
      "12/22/2023 12:31:03 - INFO - llmtuner.model.parser - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=False,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=True,\n",
      "dispatch_batches=None,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "fp16=True,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_config=None,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=4,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=saves/Qwen-7B/lora/train_2023-12-22-12-30-35/runs/Dec22_12-31-03_0d29e2836749,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=5,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=cosine,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=0,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "output_dir=saves/Qwen-7B/lora/train_2023-12-22-12-30-35,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=False,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=saves/Qwen-7B/lora/train_2023-12-22-12-30-35,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=100,\n",
      "save_strategy=steps,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "sortish_sampler=False,\n",
      "split_batches=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "12/22/2023 12:31:03 - INFO - llmtuner.data.loader - Loading dataset llama_factory_train_data.json...\n",
      "12/22/2023 12:31:03 - WARNING - llmtuner.data.utils - Checksum failed: missing SHA-1 hash value in dataset_info.json.\n",
      "Using custom data configuration default-530a8f2f20ab0a17\n",
      "Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n",
      "Generating dataset json (/root/.cache/huggingface/datasets/json/default-530a8f2f20ab0a17/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-530a8f2f20ab0a17/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96...\n",
      "Downloading data files: 100% 1/1 [00:00<00:00, 12748.64it/s]\n",
      "Downloading took 0.0 min\n",
      "Checksum Computation took 0.0 min\n",
      "Extracting data files: 100% 1/1 [00:00<00:00, 1454.34it/s]\n",
      "Generating train split\n",
      "Generating train split: 8659 examples [00:00, 22748.01 examples/s]\n",
      "Unable to verify splits sizes.\n",
      "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-530a8f2f20ab0a17/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96. Subsequent calls will reuse this data.\n",
      "Converting format of dataset:   0% 0/8659 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-530a8f2f20ab0a17/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3e69356574c62eac.arrow\n",
      "Converting format of dataset: 100% 8659/8659 [00:00<00:00, 43429.23 examples/s]\n",
      "tokenizer_config.json: 100% 174/174 [00:00<00:00, 938kB/s]\n",
      "tokenization_qwen.py: 100% 9.62k/9.62k [00:00<00:00, 31.6MB/s]\n",
      "qwen.tiktoken: 100% 2.56M/2.56M [00:00<00:00, 5.18MB/s]\n",
      "[INFO|tokenization_utils_base.py:2026] 2023-12-22 12:31:07,187 >> loading file qwen.tiktoken from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen-7B/snapshots/ffe04dd57f85293043ba999a2c0daa788d6182e9/qwen.tiktoken\n",
      "[INFO|tokenization_utils_base.py:2026] 2023-12-22 12:31:07,188 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2026] 2023-12-22 12:31:07,188 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2026] 2023-12-22 12:31:07,188 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen-7B/snapshots/ffe04dd57f85293043ba999a2c0daa788d6182e9/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2026] 2023-12-22 12:31:07,188 >> loading file tokenizer.json from cache at None\n",
      "config.json: 100% 911/911 [00:00<00:00, 5.77MB/s]\n",
      "[INFO|configuration_utils.py:739] 2023-12-22 12:31:07,748 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen-7B/snapshots/ffe04dd57f85293043ba999a2c0daa788d6182e9/config.json\n",
      "configuration_qwen.py: 100% 2.35k/2.35k [00:00<00:00, 13.6MB/s]\n",
      "[INFO|configuration_utils.py:739] 2023-12-22 12:31:08,062 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen-7B/snapshots/ffe04dd57f85293043ba999a2c0daa788d6182e9/config.json\n",
      "[INFO|configuration_utils.py:802] 2023-12-22 12:31:08,063 >> Model config QWenConfig {\n",
      "  \"_name_or_path\": \"Qwen/Qwen-7B\",\n",
      "  \"architectures\": [\n",
      "    \"QWenLMHeadModel\"\n",
      "  ],\n",
      "  \"attn_dropout_prob\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"Qwen/Qwen-7B--configuration_qwen.QWenConfig\",\n",
      "    \"AutoModelForCausalLM\": \"Qwen/Qwen-7B--modeling_qwen.QWenLMHeadModel\"\n",
      "  },\n",
      "  \"bf16\": false,\n",
      "  \"emb_dropout_prob\": 0.0,\n",
      "  \"fp16\": false,\n",
      "  \"fp32\": false,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 22016,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"qwen\",\n",
      "  \"no_bias\": true,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"onnx_safe\": null,\n",
      "  \"rotary_emb_base\": 10000,\n",
      "  \"rotary_pct\": 1.0,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"softmax_in_fp32\": false,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"tokenizer_class\": \"QWenTokenizer\",\n",
      "  \"transformers_version\": \"4.36.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_cache_kernel\": false,\n",
      "  \"use_cache_quantization\": false,\n",
      "  \"use_dynamic_ntk\": true,\n",
      "  \"use_flash_attn\": \"auto\",\n",
      "  \"use_logn_attn\": true,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "modeling_qwen.py: 100% 55.6k/55.6k [00:00<00:00, 69.2MB/s]\n",
      "cpp_kernels.py: 100% 1.92k/1.92k [00:00<00:00, 12.5MB/s]\n",
      "qwen_generation_utils.py: 100% 14.6k/14.6k [00:00<00:00, 62.6MB/s]\n",
      "model.safetensors.index.json: 100% 19.5k/19.5k [00:00<00:00, 73.9MB/s]\n",
      "[INFO|modeling_utils.py:3344] 2023-12-22 12:31:09,152 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen-7B/snapshots/ffe04dd57f85293043ba999a2c0daa788d6182e9/model.safetensors.index.json\n",
      "Downloading shards:   0% 0/8 [00:00<?, ?it/s]\n",
      "model-00001-of-00008.safetensors:   0% 0.00/1.96G [00:00<?, ?B/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:   1% 10.5M/1.96G [00:00<00:27, 71.5MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:   2% 31.5M/1.96G [00:00<00:14, 129MB/s] \u001B[A\n",
      "model-00001-of-00008.safetensors:   3% 62.9M/1.96G [00:00<00:09, 197MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:   5% 94.4M/1.96G [00:00<00:08, 231MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:   6% 126M/1.96G [00:00<00:07, 258MB/s] \u001B[A\n",
      "model-00001-of-00008.safetensors:   9% 168M/1.96G [00:00<00:05, 300MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  10% 199M/1.96G [00:00<00:06, 294MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  12% 231M/1.96G [00:00<00:06, 286MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  13% 262M/1.96G [00:01<00:06, 281MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  15% 294M/1.96G [00:01<00:05, 279MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  17% 325M/1.96G [00:01<00:05, 283MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  18% 357M/1.96G [00:01<00:05, 291MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  20% 398M/1.96G [00:01<00:05, 310MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  22% 440M/1.96G [00:01<00:05, 300MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  24% 472M/1.96G [00:01<00:05, 283MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  26% 503M/1.96G [00:01<00:05, 273MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  27% 535M/1.96G [00:01<00:05, 279MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  29% 566M/1.96G [00:02<00:05, 276MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  30% 598M/1.96G [00:02<00:04, 281MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  32% 629M/1.96G [00:02<00:04, 278MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  34% 661M/1.96G [00:02<00:04, 276MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  35% 692M/1.96G [00:02<00:04, 279MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  37% 724M/1.96G [00:02<00:04, 280MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  39% 765M/1.96G [00:02<00:04, 294MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  41% 807M/1.96G [00:02<00:03, 306MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  43% 849M/1.96G [00:03<00:03, 310MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  45% 881M/1.96G [00:03<00:03, 299MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  46% 912M/1.96G [00:03<00:03, 298MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  48% 944M/1.96G [00:03<00:03, 301MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  50% 975M/1.96G [00:03<00:03, 299MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  51% 1.01G/1.96G [00:03<00:03, 296MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  53% 1.05G/1.96G [00:03<00:03, 299MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  55% 1.08G/1.96G [00:03<00:02, 299MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  57% 1.11G/1.96G [00:03<00:02, 298MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  58% 1.14G/1.96G [00:04<00:02, 298MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  60% 1.18G/1.96G [00:04<00:02, 307MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  62% 1.23G/1.96G [00:04<00:02, 310MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  64% 1.26G/1.96G [00:04<00:02, 308MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  66% 1.29G/1.96G [00:04<00:02, 300MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  68% 1.33G/1.96G [00:04<00:02, 307MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  70% 1.37G/1.96G [00:04<00:01, 317MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  72% 1.42G/1.96G [00:04<00:01, 314MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  74% 1.46G/1.96G [00:05<00:01, 319MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  76% 1.50G/1.96G [00:05<00:01, 278MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  78% 1.53G/1.96G [00:05<00:01, 263MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  80% 1.56G/1.96G [00:05<00:01, 255MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  81% 1.59G/1.96G [00:05<00:01, 260MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  83% 1.63G/1.96G [00:05<00:01, 272MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  85% 1.67G/1.96G [00:05<00:01, 290MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  87% 1.71G/1.96G [00:05<00:00, 310MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  89% 1.75G/1.96G [00:06<00:00, 323MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  91% 1.79G/1.96G [00:06<00:00, 323MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  93% 1.84G/1.96G [00:06<00:00, 324MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  96% 1.88G/1.96G [00:06<00:00, 337MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors:  98% 1.92G/1.96G [00:06<00:00, 349MB/s]\u001B[A\n",
      "model-00001-of-00008.safetensors: 100% 1.96G/1.96G [00:06<00:00, 290MB/s]\n",
      "Downloading shards:  12% 1/8 [00:07<00:49,  7.00s/it]\n",
      "model-00002-of-00008.safetensors:   0% 0.00/2.02G [00:00<?, ?B/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:   1% 21.0M/2.02G [00:00<00:11, 168MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:   3% 52.4M/2.02G [00:00<00:08, 243MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:   5% 94.4M/2.02G [00:00<00:06, 285MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:   7% 136M/2.02G [00:00<00:05, 317MB/s] \u001B[A\n",
      "model-00002-of-00008.safetensors:   9% 178M/2.02G [00:00<00:05, 331MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  11% 220M/2.02G [00:00<00:05, 346MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  13% 262M/2.02G [00:00<00:04, 354MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  15% 304M/2.02G [00:00<00:04, 364MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  17% 346M/2.02G [00:01<00:04, 368MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  19% 388M/2.02G [00:01<00:04, 368MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  21% 430M/2.02G [00:01<00:04, 356MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  23% 472M/2.02G [00:01<00:04, 346MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  25% 514M/2.02G [00:01<00:04, 326MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  27% 556M/2.02G [00:01<00:04, 330MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  30% 598M/2.02G [00:01<00:04, 331MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  32% 640M/2.02G [00:01<00:04, 331MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  34% 682M/2.02G [00:02<00:04, 326MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  36% 724M/2.02G [00:02<00:04, 320MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  38% 765M/2.02G [00:02<00:03, 317MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  40% 807M/2.02G [00:02<00:03, 308MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  41% 839M/2.02G [00:02<00:03, 307MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  44% 881M/2.02G [00:02<00:03, 317MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  46% 923M/2.02G [00:02<00:03, 323MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  48% 965M/2.02G [00:02<00:03, 327MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  50% 1.01G/2.02G [00:03<00:03, 320MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  52% 1.05G/2.02G [00:03<00:04, 214MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  54% 1.09G/2.02G [00:03<00:03, 240MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  56% 1.13G/2.02G [00:03<00:03, 260MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  58% 1.17G/2.02G [00:03<00:02, 286MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  60% 1.22G/2.02G [00:03<00:02, 298MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  62% 1.26G/2.02G [00:04<00:02, 316MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  64% 1.30G/2.02G [00:04<00:02, 330MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  66% 1.34G/2.02G [00:04<00:01, 342MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  68% 1.38G/2.02G [00:04<00:01, 347MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  70% 1.43G/2.02G [00:04<00:01, 354MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  73% 1.47G/2.02G [00:04<00:01, 325MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  75% 1.51G/2.02G [00:04<00:01, 313MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  77% 1.55G/2.02G [00:04<00:01, 312MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  79% 1.59G/2.02G [00:05<00:01, 326MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  81% 1.64G/2.02G [00:05<00:01, 335MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  83% 1.68G/2.02G [00:05<00:01, 342MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  85% 1.72G/2.02G [00:05<00:00, 306MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  87% 1.76G/2.02G [00:05<00:00, 314MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  89% 1.80G/2.02G [00:05<00:00, 330MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  91% 1.85G/2.02G [00:05<00:00, 335MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  93% 1.89G/2.02G [00:05<00:00, 334MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  95% 1.93G/2.02G [00:06<00:00, 348MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors:  97% 1.97G/2.02G [00:06<00:00, 340MB/s]\u001B[A\n",
      "model-00002-of-00008.safetensors: 100% 2.02G/2.02G [00:06<00:00, 319MB/s]\n",
      "Downloading shards:  25% 2/8 [00:13<00:40,  6.69s/it]\n",
      "model-00003-of-00008.safetensors:   0% 0.00/2.02G [00:00<?, ?B/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:   1% 21.0M/2.02G [00:00<00:11, 174MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:   3% 52.4M/2.02G [00:00<00:08, 223MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:   4% 83.9M/2.02G [00:00<00:07, 254MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:   6% 115M/2.02G [00:00<00:07, 273MB/s] \u001B[A\n",
      "model-00003-of-00008.safetensors:   8% 157M/2.02G [00:00<00:06, 299MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  10% 199M/2.02G [00:00<00:06, 300MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  11% 231M/2.02G [00:00<00:08, 215MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  13% 262M/2.02G [00:01<00:07, 229MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  15% 294M/2.02G [00:01<00:07, 238MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  17% 336M/2.02G [00:01<00:06, 267MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  18% 367M/2.02G [00:01<00:06, 272MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  20% 409M/2.02G [00:01<00:05, 292MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  22% 440M/2.02G [00:01<00:07, 218MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  23% 472M/2.02G [00:02<00:08, 183MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  25% 503M/2.02G [00:02<00:08, 171MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  26% 524M/2.02G [00:02<00:10, 143MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  27% 556M/2.02G [00:02<00:08, 167MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  28% 577M/2.02G [00:02<00:08, 170MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  30% 598M/2.02G [00:02<00:08, 168MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  31% 619M/2.02G [00:02<00:07, 176MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  32% 640M/2.02G [00:03<00:07, 183MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  33% 671M/2.02G [00:03<00:06, 194MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  34% 692M/2.02G [00:03<00:06, 195MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  35% 713M/2.02G [00:03<00:07, 187MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  37% 744M/2.02G [00:03<00:06, 200MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  38% 776M/2.02G [00:03<00:05, 213MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  40% 807M/2.02G [00:03<00:05, 224MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  41% 839M/2.02G [00:03<00:05, 231MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  43% 870M/2.02G [00:04<00:04, 232MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  45% 902M/2.02G [00:04<00:04, 232MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  46% 933M/2.02G [00:04<00:04, 235MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  48% 965M/2.02G [00:04<00:04, 217MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  49% 996M/2.02G [00:04<00:04, 232MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  51% 1.03G/2.02G [00:04<00:03, 249MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  52% 1.06G/2.02G [00:04<00:04, 225MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  54% 1.09G/2.02G [00:05<00:04, 233MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  55% 1.12G/2.02G [00:05<00:03, 231MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  57% 1.15G/2.02G [00:05<00:03, 236MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  59% 1.18G/2.02G [00:05<00:03, 244MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  60% 1.22G/2.02G [00:05<00:03, 252MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  62% 1.26G/2.02G [00:05<00:02, 277MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  64% 1.30G/2.02G [00:05<00:02, 286MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  66% 1.33G/2.02G [00:05<00:02, 293MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  68% 1.37G/2.02G [00:06<00:02, 302MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  69% 1.41G/2.02G [00:06<00:02, 303MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  71% 1.45G/2.02G [00:06<00:01, 310MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  74% 1.49G/2.02G [00:06<00:01, 321MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  76% 1.53G/2.02G [00:06<00:01, 314MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  77% 1.56G/2.02G [00:06<00:01, 296MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  79% 1.59G/2.02G [00:06<00:01, 270MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  80% 1.63G/2.02G [00:06<00:01, 276MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  82% 1.66G/2.02G [00:07<00:01, 275MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  83% 1.69G/2.02G [00:07<00:01, 279MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  85% 1.72G/2.02G [00:07<00:01, 283MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  87% 1.76G/2.02G [00:07<00:00, 306MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  89% 1.80G/2.02G [00:07<00:00, 324MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  91% 1.85G/2.02G [00:07<00:00, 326MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  93% 1.89G/2.02G [00:07<00:00, 339MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  95% 1.93G/2.02G [00:07<00:00, 286MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors:  97% 1.96G/2.02G [00:08<00:00, 279MB/s]\u001B[A\n",
      "model-00003-of-00008.safetensors: 100% 2.02G/2.02G [00:08<00:00, 246MB/s]\n",
      "Downloading shards:  38% 3/8 [00:21<00:37,  7.44s/it]\n",
      "model-00004-of-00008.safetensors:   0% 0.00/2.02G [00:00<?, ?B/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:   1% 10.5M/2.02G [00:00<00:21, 91.7MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:   2% 31.5M/2.02G [00:00<00:12, 157MB/s] \u001B[A\n",
      "model-00004-of-00008.safetensors:   3% 62.9M/2.02G [00:00<00:09, 215MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:   5% 94.4M/2.02G [00:00<00:07, 245MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:   6% 126M/2.02G [00:00<00:07, 262MB/s] \u001B[A\n",
      "model-00004-of-00008.safetensors:   8% 168M/2.02G [00:00<00:06, 286MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  10% 210M/2.02G [00:00<00:05, 315MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  12% 252M/2.02G [00:00<00:05, 336MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  15% 294M/2.02G [00:01<00:05, 344MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  17% 336M/2.02G [00:01<00:04, 347MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  19% 377M/2.02G [00:01<00:05, 311MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  21% 419M/2.02G [00:01<00:05, 315MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  23% 461M/2.02G [00:01<00:04, 314MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  25% 503M/2.02G [00:01<00:04, 319MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  27% 545M/2.02G [00:01<00:04, 307MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  29% 587M/2.02G [00:01<00:04, 314MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  31% 629M/2.02G [00:02<00:04, 321MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  33% 671M/2.02G [00:02<00:04, 315MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  35% 713M/2.02G [00:02<00:04, 325MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  37% 755M/2.02G [00:02<00:03, 330MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  39% 797M/2.02G [00:02<00:03, 325MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  41% 839M/2.02G [00:02<00:03, 319MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  44% 881M/2.02G [00:02<00:03, 320MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  46% 923M/2.02G [00:02<00:03, 321MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  48% 965M/2.02G [00:03<00:03, 315MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  50% 1.01G/2.02G [00:03<00:03, 303MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  51% 1.04G/2.02G [00:03<00:03, 299MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  53% 1.07G/2.02G [00:03<00:03, 296MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  54% 1.10G/2.02G [00:03<00:03, 299MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  56% 1.13G/2.02G [00:03<00:02, 302MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  58% 1.17G/2.02G [00:03<00:02, 311MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  60% 1.22G/2.02G [00:03<00:02, 327MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  62% 1.26G/2.02G [00:04<00:02, 333MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  64% 1.30G/2.02G [00:04<00:02, 327MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  66% 1.34G/2.02G [00:04<00:03, 222MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  68% 1.38G/2.02G [00:04<00:02, 255MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  70% 1.43G/2.02G [00:04<00:02, 270MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  72% 1.46G/2.02G [00:04<00:02, 279MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  74% 1.49G/2.02G [00:05<00:02, 255MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  75% 1.52G/2.02G [00:05<00:01, 253MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  77% 1.55G/2.02G [00:05<00:01, 262MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  79% 1.59G/2.02G [00:05<00:01, 284MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  81% 1.64G/2.02G [00:05<00:01, 309MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  83% 1.68G/2.02G [00:05<00:01, 284MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  85% 1.72G/2.02G [00:05<00:01, 290MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  87% 1.75G/2.02G [00:05<00:00, 288MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  89% 1.79G/2.02G [00:06<00:00, 310MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  91% 1.84G/2.02G [00:06<00:00, 321MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  93% 1.88G/2.02G [00:06<00:00, 335MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  95% 1.92G/2.02G [00:06<00:00, 339MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors:  97% 1.96G/2.02G [00:06<00:00, 349MB/s]\u001B[A\n",
      "model-00004-of-00008.safetensors: 100% 2.02G/2.02G [00:06<00:00, 298MB/s]\n",
      "Downloading shards:  50% 4/8 [00:28<00:28,  7.23s/it]\n",
      "model-00005-of-00008.safetensors:   0% 0.00/2.02G [00:00<?, ?B/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:   1% 21.0M/2.02G [00:00<00:12, 165MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:   3% 52.4M/2.02G [00:00<00:09, 202MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:   4% 83.9M/2.02G [00:00<00:08, 225MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:   6% 115M/2.02G [00:00<00:07, 239MB/s] \u001B[A\n",
      "model-00005-of-00008.safetensors:   7% 147M/2.02G [00:00<00:07, 249MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:   9% 178M/2.02G [00:00<00:07, 253MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  10% 210M/2.02G [00:00<00:06, 261MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  12% 241M/2.02G [00:00<00:06, 272MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  13% 273M/2.02G [00:01<00:06, 273MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  15% 304M/2.02G [00:01<00:06, 282MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  17% 336M/2.02G [00:01<00:05, 291MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  18% 367M/2.02G [00:01<00:05, 292MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  20% 409M/2.02G [00:01<00:05, 305MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  22% 451M/2.02G [00:01<00:04, 317MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  24% 493M/2.02G [00:01<00:04, 324MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  26% 535M/2.02G [00:01<00:04, 319MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  28% 577M/2.02G [00:02<00:04, 317MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  31% 619M/2.02G [00:02<00:04, 328MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  33% 661M/2.02G [00:02<00:04, 338MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  35% 703M/2.02G [00:02<00:03, 346MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  37% 744M/2.02G [00:02<00:03, 331MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  39% 786M/2.02G [00:02<00:03, 317MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  41% 828M/2.02G [00:02<00:03, 327MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  43% 870M/2.02G [00:02<00:03, 320MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  45% 912M/2.02G [00:03<00:03, 330MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  47% 954M/2.02G [00:03<00:03, 322MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  49% 996M/2.02G [00:03<00:03, 331MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  51% 1.04G/2.02G [00:03<00:03, 327MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  53% 1.08G/2.02G [00:03<00:02, 326MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  55% 1.12G/2.02G [00:03<00:02, 336MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  58% 1.16G/2.02G [00:03<00:02, 315MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  60% 1.21G/2.02G [00:03<00:02, 312MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  62% 1.25G/2.02G [00:04<00:02, 327MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  64% 1.29G/2.02G [00:04<00:02, 322MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  66% 1.33G/2.02G [00:04<00:02, 322MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  68% 1.37G/2.02G [00:04<00:02, 318MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  70% 1.42G/2.02G [00:04<00:01, 324MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  72% 1.46G/2.02G [00:04<00:01, 328MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  74% 1.50G/2.02G [00:04<00:01, 330MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  76% 1.54G/2.02G [00:05<00:01, 278MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  78% 1.57G/2.02G [00:05<00:01, 277MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  79% 1.60G/2.02G [00:05<00:01, 275MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  81% 1.65G/2.02G [00:05<00:01, 291MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  83% 1.68G/2.02G [00:05<00:01, 295MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  85% 1.72G/2.02G [00:05<00:01, 298MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  87% 1.76G/2.02G [00:05<00:00, 305MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  89% 1.79G/2.02G [00:05<00:00, 305MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  91% 1.84G/2.02G [00:06<00:00, 312MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  93% 1.88G/2.02G [00:06<00:00, 316MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  95% 1.92G/2.02G [00:06<00:00, 318MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  97% 1.96G/2.02G [00:06<00:00, 308MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors:  98% 1.99G/2.02G [00:06<00:00, 281MB/s]\u001B[A\n",
      "model-00005-of-00008.safetensors: 100% 2.02G/2.02G [00:06<00:00, 301MB/s]\n",
      "Downloading shards:  62% 5/8 [00:35<00:21,  7.10s/it]\n",
      "model-00006-of-00008.safetensors:   0% 0.00/2.02G [00:00<?, ?B/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:   1% 21.0M/2.02G [00:00<00:13, 146MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:   3% 52.4M/2.02G [00:00<00:09, 215MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:   4% 83.9M/2.02G [00:00<00:07, 249MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:   6% 115M/2.02G [00:00<00:07, 249MB/s] \u001B[A\n",
      "model-00006-of-00008.safetensors:   8% 157M/2.02G [00:00<00:06, 278MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:   9% 189M/2.02G [00:00<00:06, 285MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  11% 220M/2.02G [00:00<00:06, 293MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  13% 262M/2.02G [00:00<00:05, 320MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  15% 304M/2.02G [00:01<00:05, 325MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  17% 346M/2.02G [00:01<00:05, 303MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  19% 377M/2.02G [00:01<00:05, 285MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  20% 409M/2.02G [00:01<00:05, 285MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  22% 440M/2.02G [00:01<00:05, 288MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  23% 472M/2.02G [00:01<00:05, 291MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  25% 503M/2.02G [00:01<00:05, 296MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  26% 535M/2.02G [00:01<00:04, 299MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  28% 566M/2.02G [00:01<00:04, 295MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  30% 608M/2.02G [00:02<00:04, 309MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  32% 650M/2.02G [00:02<00:04, 327MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  34% 692M/2.02G [00:02<00:04, 306MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  36% 724M/2.02G [00:02<00:04, 308MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  37% 755M/2.02G [00:02<00:04, 302MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  39% 786M/2.02G [00:02<00:04, 303MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  41% 828M/2.02G [00:02<00:03, 309MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  42% 860M/2.02G [00:02<00:03, 297MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  45% 902M/2.02G [00:03<00:03, 312MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  47% 944M/2.02G [00:03<00:03, 319MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  49% 986M/2.02G [00:03<00:03, 308MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  50% 1.02G/2.02G [00:03<00:03, 271MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  52% 1.05G/2.02G [00:03<00:03, 262MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  53% 1.08G/2.02G [00:03<00:03, 258MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  55% 1.12G/2.02G [00:03<00:03, 271MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  57% 1.15G/2.02G [00:03<00:03, 274MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  59% 1.20G/2.02G [00:04<00:02, 283MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  61% 1.23G/2.02G [00:04<00:02, 290MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  62% 1.26G/2.02G [00:04<00:02, 296MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  64% 1.29G/2.02G [00:04<00:02, 298MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  65% 1.32G/2.02G [00:04<00:02, 289MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  67% 1.35G/2.02G [00:04<00:02, 291MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  68% 1.38G/2.02G [00:04<00:02, 287MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  70% 1.42G/2.02G [00:04<00:02, 261MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  71% 1.45G/2.02G [00:05<00:02, 259MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  73% 1.48G/2.02G [00:05<00:02, 259MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  75% 1.51G/2.02G [00:05<00:01, 263MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  77% 1.55G/2.02G [00:05<00:01, 292MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  79% 1.59G/2.02G [00:05<00:01, 315MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  81% 1.64G/2.02G [00:05<00:01, 331MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  83% 1.68G/2.02G [00:05<00:01, 340MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  85% 1.72G/2.02G [00:05<00:00, 314MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  87% 1.76G/2.02G [00:06<00:00, 314MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  89% 1.80G/2.02G [00:06<00:00, 314MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  91% 1.85G/2.02G [00:06<00:00, 289MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  93% 1.88G/2.02G [00:06<00:00, 274MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  94% 1.91G/2.02G [00:06<00:00, 278MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  96% 1.94G/2.02G [00:06<00:00, 265MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors:  97% 1.97G/2.02G [00:06<00:00, 256MB/s]\u001B[A\n",
      "model-00006-of-00008.safetensors: 100% 2.02G/2.02G [00:07<00:00, 287MB/s]\n",
      "Downloading shards:  75% 6/8 [00:42<00:14,  7.12s/it]\n",
      "model-00007-of-00008.safetensors:   0% 0.00/2.02G [00:00<?, ?B/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:   1% 21.0M/2.02G [00:00<00:12, 159MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:   3% 52.4M/2.02G [00:00<00:08, 227MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:   4% 83.9M/2.02G [00:00<00:07, 246MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:   6% 115M/2.02G [00:00<00:07, 249MB/s] \u001B[A\n",
      "model-00007-of-00008.safetensors:   8% 157M/2.02G [00:00<00:06, 280MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  10% 199M/2.02G [00:00<00:06, 300MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  12% 241M/2.02G [00:00<00:05, 308MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  14% 283M/2.02G [00:00<00:05, 318MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  16% 325M/2.02G [00:01<00:05, 315MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  18% 367M/2.02G [00:01<00:05, 289MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  20% 409M/2.02G [00:01<00:05, 305MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  22% 440M/2.02G [00:01<00:05, 266MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  23% 472M/2.02G [00:01<00:06, 255MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  25% 503M/2.02G [00:01<00:05, 260MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  26% 535M/2.02G [00:01<00:05, 267MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  28% 566M/2.02G [00:02<00:05, 261MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  30% 598M/2.02G [00:02<00:05, 265MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  31% 629M/2.02G [00:02<00:05, 250MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  33% 661M/2.02G [00:02<00:06, 222MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  34% 692M/2.02G [00:02<00:05, 235MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  36% 724M/2.02G [00:02<00:05, 249MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  37% 755M/2.02G [00:02<00:05, 247MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  39% 786M/2.02G [00:02<00:05, 244MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  40% 818M/2.02G [00:03<00:04, 255MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  42% 849M/2.02G [00:03<00:04, 263MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  44% 881M/2.02G [00:03<00:04, 275MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  46% 923M/2.02G [00:03<00:03, 293MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  47% 954M/2.02G [00:03<00:03, 275MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  49% 986M/2.02G [00:03<00:03, 278MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  50% 1.02G/2.02G [00:03<00:03, 278MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  52% 1.06G/2.02G [00:03<00:03, 288MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  54% 1.10G/2.02G [00:04<00:03, 300MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  56% 1.14G/2.02G [00:04<00:02, 307MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  58% 1.17G/2.02G [00:04<00:02, 293MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  60% 1.21G/2.02G [00:04<00:03, 258MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  61% 1.24G/2.02G [00:04<00:03, 248MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  63% 1.27G/2.02G [00:04<00:02, 255MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  64% 1.30G/2.02G [00:04<00:02, 260MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  66% 1.33G/2.02G [00:04<00:02, 269MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  67% 1.36G/2.02G [00:05<00:03, 177MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  69% 1.39G/2.02G [00:05<00:03, 197MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  71% 1.44G/2.02G [00:05<00:02, 220MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  73% 1.47G/2.02G [00:05<00:02, 213MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  74% 1.50G/2.02G [00:05<00:02, 225MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  76% 1.53G/2.02G [00:05<00:02, 232MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  77% 1.56G/2.02G [00:06<00:01, 239MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  79% 1.59G/2.02G [00:06<00:01, 229MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  80% 1.63G/2.02G [00:06<00:01, 241MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  82% 1.66G/2.02G [00:06<00:01, 237MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  84% 1.70G/2.02G [00:06<00:01, 251MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  85% 1.73G/2.02G [00:06<00:01, 263MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  88% 1.77G/2.02G [00:06<00:00, 269MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  89% 1.80G/2.02G [00:06<00:00, 268MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  91% 1.84G/2.02G [00:07<00:00, 266MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  92% 1.87G/2.02G [00:07<00:00, 271MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  94% 1.90G/2.02G [00:07<00:00, 280MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  95% 1.93G/2.02G [00:07<00:00, 284MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors:  97% 1.96G/2.02G [00:07<00:00, 292MB/s]\u001B[A\n",
      "model-00007-of-00008.safetensors: 100% 2.02G/2.02G [00:07<00:00, 262MB/s]\n",
      "Downloading shards:  88% 7/8 [00:50<00:07,  7.39s/it]\n",
      "model-00008-of-00008.safetensors:   0% 0.00/1.33G [00:00<?, ?B/s]\u001B[A\n",
      "model-00008-of-00008.safetensors:   3% 41.9M/1.33G [00:00<00:03, 375MB/s]\u001B[A\n",
      "model-00008-of-00008.safetensors:   6% 83.9M/1.33G [00:00<00:03, 377MB/s]\u001B[A\n",
      "model-00008-of-00008.safetensors:   9% 126M/1.33G [00:00<00:03, 376MB/s] \u001B[A\n",
      "model-00008-of-00008.safetensors:  13% 168M/1.33G [00:00<00:03, 355MB/s]\u001B[A\n",
      "model-00008-of-00008.safetensors:  16% 210M/1.33G [00:00<00:03, 360MB/s]\u001B[A\n",
      "model-00008-of-00008.safetensors:  19% 252M/1.33G [00:00<00:02, 368MB/s]\u001B[A\n",
      "model-00008-of-00008.safetensors:  22% 294M/1.33G [00:00<00:02, 370MB/s]\u001B[A\n",
      "model-00008-of-00008.safetensors:  25% 336M/1.33G [00:00<00:02, 361MB/s]\u001B[A\n",
      "model-00008-of-00008.safetensors:  28% 377M/1.33G [00:01<00:02, 348MB/s]\u001B[A\n",
      "model-00008-of-00008.safetensors:  31% 419M/1.33G [00:01<00:02, 331MB/s]\u001B[A\n",
      "model-00008-of-00008.safetensors:  35% 461M/1.33G [00:01<00:02, 316MB/s]\u001B[A\n",
      "model-00008-of-00008.safetensors:  38% 503M/1.33G [00:01<00:02, 311MB/s]\u001B[A\n",
      "model-00008-of-00008.safetensors:  41% 545M/1.33G [00:01<00:02, 315MB/s]\u001B[A\n",
      "model-00008-of-00008.safetensors:  44% 587M/1.33G [00:01<00:02, 316MB/s]\u001B[A\n",
      "model-00008-of-00008.safetensors:  47% 629M/1.33G [00:01<00:02, 313MB/s]\u001B[A\n",
      "model-00008-of-00008.safetensors:  49% 661M/1.33G [00:01<00:02, 312MB/s]\u001B[A\n",
      "model-00008-of-00008.safetensors:  52% 692M/1.33G [00:02<00:02, 310MB/s]\u001B[A\n",
      "model-00008-of-00008.safetensors:  54% 724M/1.33G [00:02<00:02, 303MB/s]\u001B[A\n",
      "model-00008-of-00008.safetensors:  57% 755M/1.33G [00:02<00:01, 298MB/s]\u001B[A\n",
      "model-00008-of-00008.safetensors:  59% 786M/1.33G [00:02<00:01, 302MB/s]\u001B[A\n",
      "model-00008-of-00008.safetensors:  62% 828M/1.33G [00:02<00:01, 308MB/s]\u001B[A\n",
      "model-00008-of-00008.safetensors:  65% 870M/1.33G [00:02<00:01, 317MB/s]\u001B[A\n",
      "model-00008-of-00008.safetensors:  68% 912M/1.33G [00:02<00:01, 315MB/s]\u001B[A\n",
      "model-00008-of-00008.safetensors:  71% 944M/1.33G [00:02<00:01, 299MB/s]\u001B[A\n",
      "model-00008-of-00008.safetensors:  74% 986M/1.33G [00:03<00:01, 307MB/s]\u001B[A\n",
      "model-00008-of-00008.safetensors:  77% 1.03G/1.33G [00:03<00:00, 314MB/s]\u001B[A\n",
      "model-00008-of-00008.safetensors:  80% 1.07G/1.33G [00:03<00:00, 316MB/s]\u001B[A\n",
      "model-00008-of-00008.safetensors:  83% 1.11G/1.33G [00:03<00:00, 310MB/s]\u001B[A\n",
      "model-00008-of-00008.safetensors:  86% 1.15G/1.33G [00:03<00:00, 318MB/s]\u001B[A\n",
      "model-00008-of-00008.safetensors:  90% 1.20G/1.33G [00:03<00:00, 321MB/s]\u001B[A\n",
      "model-00008-of-00008.safetensors:  93% 1.24G/1.33G [00:03<00:00, 323MB/s]\u001B[A\n",
      "model-00008-of-00008.safetensors:  96% 1.28G/1.33G [00:03<00:00, 319MB/s]\u001B[A\n",
      "model-00008-of-00008.safetensors: 100% 1.33G/1.33G [00:04<00:00, 323MB/s]\n",
      "Downloading shards: 100% 8/8 [00:54<00:00,  6.87s/it]\n",
      "[INFO|modeling_utils.py:1341] 2023-12-22 12:32:04,103 >> Instantiating QWenLMHeadModel model under default dtype torch.float16.\n",
      "[INFO|configuration_utils.py:826] 2023-12-22 12:32:04,104 >> Generate config GenerationConfig {}\n",
      "\n",
      "Loading checkpoint shards: 100% 8/8 [00:05<00:00,  1.34it/s]\n",
      "[INFO|modeling_utils.py:4185] 2023-12-22 12:32:10,634 >> All model checkpoint weights were used when initializing QWenLMHeadModel.\n",
      "\n",
      "[INFO|modeling_utils.py:4193] 2023-12-22 12:32:10,635 >> All the weights of QWenLMHeadModel were initialized from the model checkpoint at Qwen/Qwen-7B.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use QWenLMHeadModel for predictions without further training.\n",
      "generation_config.json: 100% 222/222 [00:00<00:00, 1.23MB/s]\n",
      "[INFO|configuration_utils.py:781] 2023-12-22 12:32:10,848 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen-7B/snapshots/ffe04dd57f85293043ba999a2c0daa788d6182e9/generation_config.json\n",
      "[INFO|configuration_utils.py:826] 2023-12-22 12:32:10,848 >> Generate config GenerationConfig {\n",
      "  \"chat_format\": \"raw\",\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": 151643,\n",
      "  \"max_new_tokens\": 512,\n",
      "  \"pad_token_id\": 151643,\n",
      "  \"stop_words_ids\": [\n",
      "    [\n",
      "      151643\n",
      "    ]\n",
      "  ],\n",
      "  \"top_k\": 0,\n",
      "  \"top_p\": 0.8\n",
      "}\n",
      "\n",
      "[WARNING|modeling_utils.py:2045] 2023-12-22 12:32:10,850 >> You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n",
      "12/22/2023 12:32:10 - INFO - llmtuner.model.utils - Gradient checkpointing enabled.\n",
      "12/22/2023 12:32:10 - INFO - llmtuner.model.adapter - Fine-tuning method: LoRA\n",
      "12/22/2023 12:32:10 - INFO - llmtuner.model.loader - trainable params: 4194304 || all params: 7725518848 || trainable%: 0.0543\n",
      "12/22/2023 12:32:10 - INFO - llmtuner.data.template - Add eos token: <|endoftext|>\n",
      "12/22/2023 12:32:10 - INFO - llmtuner.data.template - Add pad token: <|endoftext|>\n",
      "Running tokenizer on dataset:   0% 0/8659 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-530a8f2f20ab0a17/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ec3c2517502bd10a.arrow\n",
      "Running tokenizer on dataset: 100% 8659/8659 [00:03<00:00, 2547.65 examples/s]\n",
      "input_ids:\n",
      "[22599, 14363, 1968, 320, 424, 30381, 8, 198, 33975, 25, 18137, 225, 101, 64689, 105656, 100430, 17340, 102185, 107043, 20, 21, 92015, 94432, 71703, 25, 4858, 1760, 28671, 4295, 1968, 5288, 4231, 220, 861, 220, 220, 20, 21, 151643]\n",
      "inputs:\n",
      "CREATE TABLE head (age INTEGER)\n",
      "Human: 部门中有多少人年龄大于56岁？\n",
      "Assistant:SELECT count(*) FROM head WHERE age  >  56<|endoftext|>\n",
      "label_ids:\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 4858, 1760, 28671, 4295, 1968, 5288, 4231, 220, 861, 220, 220, 20, 21, 151643]\n",
      "labels:\n",
      "SELECT count(*) FROM head WHERE age  >  56<|endoftext|>\n",
      "[INFO|training_args.py:1838] 2023-12-22 12:32:15,892 >> PyTorch: setting up devices\n",
      "[INFO|trainer.py:568] 2023-12-22 12:32:20,314 >> Using auto half precision backend\n",
      "[INFO|trainer.py:1706] 2023-12-22 12:32:20,614 >> ***** Running training *****\n",
      "[INFO|trainer.py:1707] 2023-12-22 12:32:20,614 >>   Num examples = 8,659\n",
      "[INFO|trainer.py:1708] 2023-12-22 12:32:20,614 >>   Num Epochs = 3\n",
      "[INFO|trainer.py:1709] 2023-12-22 12:32:20,614 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1712] 2023-12-22 12:32:20,614 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "[INFO|trainer.py:1713] 2023-12-22 12:32:20,614 >>   Gradient Accumulation steps = 4\n",
      "[INFO|trainer.py:1714] 2023-12-22 12:32:20,614 >>   Total optimization steps = 1,623\n",
      "[INFO|trainer.py:1715] 2023-12-22 12:32:20,615 >>   Number of trainable parameters = 4,194,304\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Exception in thread Thread-6 (run_exp):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/content/test_llama_board/src/llmtuner/train/tuner.py\", line 26, in run_exp\n",
      "    run_sft(model_args, data_args, training_args, finetuning_args, generating_args, callbacks)\n",
      "  File \"/content/test_llama_board/src/llmtuner/train/sft/workflow.py\", line 68, in run_sft\n",
      "    train_result = trainer.train(resume_from_checkpoint=training_args.resume_from_checkpoint)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 1537, in train\n",
      "    return inner_training_loop(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 1854, in _inner_training_loop\n",
      "    tr_loss_step = self.training_step(model, inputs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 2735, in training_step\n",
      "    loss = self.compute_loss(model, inputs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 2758, in compute_loss\n",
      "    outputs = model(**inputs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\", line 680, in forward\n",
      "    return model_forward(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\", line 668, in __call__\n",
      "    return convert_to_fp32(self.model_forward(*args, **kwargs))\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py\", line 16, in decorate_autocast\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\", line 1073, in forward\n",
      "    return self.base_model(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py\", line 103, in forward\n",
      "    return self.model.forward(*args, **kwargs)\n",
      "  File \"/root/.cache/huggingface/modules/transformers_modules/Qwen/Qwen-7B/ffe04dd57f85293043ba999a2c0daa788d6182e9/modeling_qwen.py\", line 1065, in forward\n",
      "    shift_logits = lm_logits[..., :-1, :].contiguous()\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacty of 15.77 GiB of which 294.38 MiB is free. Process 68491 has 15.48 GiB memory in use. Of the allocated memory 14.91 GiB is allocated by PyTorch, and 204.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# !CUDA_VISIBLE_DEVICES=0 python src/train_web.py\n",
    "!CUDA_VISIBLE_DEVICES=0 USE_MODELSCOPE_HUB=1 python src/train_web.py\n",
    "Running on local URL:  http://0.0.0.0:6006\n",
    "\n",
    "Could not create share link. Missing file: /root/miniconda3/lib/python3.8/site-packages/gradio/frpc_linux_amd64_v0.2. \n",
    "\n",
    "Please check your internet connection. This can happen if your antivirus software blocks the download of this file. You can install manually by following these steps: \n",
    "\n",
    "1. Download this file: https://cdn-media.huggingface.co/frpc-gradio-0.2/frpc_linux_amd64\n",
    "2. Rename the downloaded file to: frpc_linux_amd64_v0.2\n",
    "3. Move the file to this location: /root/miniconda3/lib/python3.8/site-packages/gradio\n",
    "^C\n",
    "Keyboard interruption in main thread... closing server."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "V100",
   "machine_shape": "hm"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
